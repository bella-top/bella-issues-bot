# 项目文件描述


- README.md: 项目主要说明文档，介绍bella-issues-bot的功能和使用方法。包含项目简介、主要功能、记忆与上下文管理系统介绍、安装方法、使用方法和环境变量配置说明。

- client/README.md: WorkflowEngine客户端文档，详细介绍了系统的记忆与上下文管理机制（日志管理、版本管理、文件记忆），支持的工作模式（客户端和机器人模式），以及命令行和编程API的使用方法和配置选项。

- client/README_FILE_MEMORY.md: 无描述

- client/README_GITHUB_WORKFLOWS.md: 该文档说明bella-issues-bot的GitHub工作流生成器功能，包括两个主要工作流：记忆初始化工作流（分析项目文件并生成描述）和Issue处理工作流（处理Issue需求并自动实现代码）。文档详细介绍了这些工作流的触发条件和功能。

- pyproject.toml: 项目配置文件，定义bella-issues-bot的元数据、依赖项和工具配置。包含项目版本、描述、作者等信息，以及Python依赖库配置、代码格式化工具设置。是项目构建和包管理的核心配置文件。

- core/workflow_engine.py: 工作流引擎核心类，协调版本管理、日志管理和AI交互。实现了处理用户需求的完整流程，支持代码生成和聊天两种工作模式，包含环境设置、清理和决策分析功能。

- core/file_memory.py: 文件记忆管理模块，负责维护和更新项目文件的描述信息。包含FileMemory类，使用AI生成文件描述，支持Git和LogManager两种方式跟踪文件变更，并批量处理文件以提高效率。与AI和Git模块紧密交互。

- client/github_workflow_generator.py: GitHub工作流生成器的核心实现，包含generate_workflow_files函数和命令行入口main函数。该模块负责生成两个YAML工作流文件：记忆初始化(memory_init.yml)和Issue处理(issue_process.yml)，支持自定义模型、分支、温度等参数。与generate_workflows.sh脚本配合使用。

- client/file_memory_client.py: 一个独立的客户端模块，用于初始化和管理FileMemory，仅使用GitManager而不依赖LogManager。提供了CLI和编程接口，实现了文件描述的更新功能。包含initialize_file_memory、update_file_descriptions等关键函数。支持命令行参数配置和环境变量加载。

- system.txt: AI系统提示词配置文件，指导AI如何编写代码，包含代码输出格式要求、diff语法规范和最佳实践指南，是AI代码生成的指导原则。


# 文件内容



```
File: README.md
1 # bella-issues-bot
2 
3 ## 项目简介
4 
5 bella-issues-bot 是一个基于人工智能的多功能代码开发助手，具备两种强大的工作模式：
6 
7 1. **个人开发助手模式**：在日常开发过程中，作为命令行工具辅助编码，帮助分析代码、生成实现、解决技术难题。
8 2. **GitHub自动化模式**：集成到GitHub工作流中，自动监控和处理项目Issues，无需人工干预即可分析需求、提出解决方案并实现代码变更。
9 
10 通过对项目结构的深入理解和强大的代码生成能力，bella-issues-bot 能够显著提高开发效率，减少重复工作，让您专注于更有创造性的任务。
11 
12 ## 主要功能
13 
14 - **需求分析**：自动理解和分解用户的功能需求
15 - **代码生成**：根据需求生成符合项目风格的代码
16 - **版本管理**：与Git集成，支持分支创建和代码提交
17 - **记忆系统**：记录项目文件描述和操作历史，提供上下文感知能力
18 
19 ## 记忆与上下文管理
20 
21 bella-issues-bot 配备了强大的记忆系统，由三个核心组件构成：
22 
23 ### 1. 日志管理 (LogManager)
24 
25 LogManager 负责记录每次交互的完整历史，包括：
26 - 系统提示词和用户需求
27 - AI响应内容
28 - 文件修改记录和差异对比
29 
30 这些日志按issue和轮次组织，支持历史追溯和问题诊断。每轮交互都会生成详细日志，便于追踪AI的决策过程和代码修改历史。
31 
32 ### 2. 版本管理 (VersionManager)
33 
34 VersionManager 提供智能的版本控制功能：
35 - 自动提取历史轮次的需求和响应
36 - 生成格式化的历史执行记录作为上下文
37 - 分析当前需求与历史需求的关系
38 - 根据需要执行版本回退操作
39 
40 系统会分析新需求与先前修改的关系，判断是否需要回滚，确保代码修改的连贯性和一致性。
41 
42 ### 3. 文件记忆 (FileMemory)
43 
44 FileMemory 模块为项目的每个文件维护详细描述：
45 - 自动生成文件功能、结构和关系描述
46 - 跟踪文件变更，更新受影响文件的描述
47 - 提供上下文相关的文件选择
48 - 支持配置忽略文件，默认包含项目的.gitignore，支持自定义添加.eng/.engignore
49 
50 这使得AI助手能够理解整个代码库的结构和功能，在修改代码时考虑到更广泛的项目上下文。
51 
52 ## 安装方法
53 
54 使用pip安装：
55 
56 ```bash
57 pip install bella-issues-bot
58 ```
59 
60 ## 使用方法
61 
62 bella-issues-bot 提供了多种使用方式：
63 
64 ### 个人开发模式
65 
66 在日常开发中，您可以通过命令行界面或编程API使用bella-issues-bot：
67 
68 #### 命令行使用
69 
70 ```bash
71 bella-issues-bot --issue-id <问题ID> --requirement "你的需求描述"
72 ```
73 
74 更多高级选项和详细使用说明，请参考[客户端文档](./client/README.md)。
75 
76 #### 编程API使用
77 
78 ```python
79 from client.runner import run_workflow
80 
81 run_workflow(
82     issue_id=42,
83     requirement="创建一个简单的README文件",
84     core_temperature=0.7
85 )
86 ```
87 
88 ## 环境变量配置
89 
90 工具会读取以下环境变量：
91 
92 - `OPENAI_API_KEY`: OpenAI API密钥
93 - `OPENAI_API_BASE`: OpenAI API基础URL
94 - `GITHUB_REMOTE_URL`: GitHub远程仓库URL
95 - `GITHUB_TOKEN`: GitHub身份验证令牌
96 - 在项目文件的.eng/目录下创建 .engignore文件，示例[examples](./.engignore.example)
97 
98 ## 示例
99 
100 可以在[examples](./examples/)目录下找到使用示例。
101 
102 ### 文件记忆初始化
103 
104 在项目根目录执行 `bella-file-memory` 可以初始化文件记忆系统，它会自动分析项目中的文件并生成描述信息。
105 更多详细信息请参阅[文件记忆客户端文档](./client/README_FILE_MEMORY.md)。
106 
107 ### GitHub工作流集成
108 
109 bella-issues-bot 提供了一个工具，可以自动为您的项目生成 GitHub Actions 工作流配置：
110 
111 ```bash
112 bella-github-workflows [选项]
113 ```
114 
115 - `--base-branch`, `-bb` - 拉取请求的目标分支（默认：main）
116 - `--model`, `-m` - 默认模型（默认：gpt-4o）
117 - `--temperature`, `-t` - 默认温度（默认：0.7）
118 
119 详细信息请参考[GitHub工作流文档](./client/README_GITHUB_WORKFLOWS.md).
120
```




```
File: client/README.md
1 # WorkflowEngine 客户端
2 
3 一个强大的命令行接口和编程API，用于运行WorkflowEngine处理用户需求，支持个人开发助手模式和GitHub自动化工作流模式。
4 
5 ## 记忆与上下文管理
6 
7 客户端依赖于强大的后台记忆系统，包括三个核心组件：
8 
9 ### 日志管理 (LogManager)
10 
11 LogManager负责存储每次交互的详细记录：
12 
13 - **结构化存储**：日志按issue ID和轮次有序组织，便于检索
14 - **完整性**：记录系统提示词、用户提示词、AI响应和文件修改
15 - **差异追踪**：保存每个修改文件的完整差异信息
16 
17 所有日志保存在项目的`.eng/memory`目录下，按照`issues/#<issue-id>/round_<num>`格式组织，可随时查看历史交互。
18 
19 ### 版本管理 (VersionManager)
20 
21 VersionManager提供智能版本控制功能：
22 
23 - **历史分析**：自动提取历史轮次的数据形成上下文
24 - **需求整合**：在新需求与历史需求有冲突时，提供智能整合
25 - **版本回退**：根据需要自动执行版本回退操作
26 
27 每次启动新的需求处理时，系统会：
28 1. 提取过去所有轮次的需求和响应
29 2. 格式化为结构化历史记录
30 3. 分析新需求与历史的关系
31 4. 决定是保持当前状态还是执行回退
32 
33 ### 文件记忆 (FileMemory)
34 
35 FileMemory为AI提供项目文件的深度理解：
36 
37 - **自动描述**：为项目中的每个文件生成功能描述
38 - **增量更新**：只更新被修改的文件描述，提高效率
39 - **批量处理**：使用智能分批策略处理大型代码库
40 - **失败处理**：对无法处理的文件提供重试机制
41 
42 当工作流运行时，系统会：
43 1. 检测新建或修改的文件
44 2. 使用AI生成这些文件的功能描述
45 3. 将描述保存在`.eng/memory/file_details.txt`中
46 4. 在后续需求处理时提供这些描述作为上下文
47 
48 ## 工作模式
49 
50 bella-issues-bot 支持两种主要工作模式：
51 
52 - **客户端模式 (client)**：默认模式，适合作为个人开发助手使用，每次运行时基于project_dir目录下的当前代码状态进行操作。
53 - **机器人模式 (bot)**：专为GitHub集成设计，会在project_dir目录下创建临时目录作为工作区，自动拉取issues对应的最新分支状态，处理完成后自动提交更改并在Issues中回复处理结果，最后清理临时工作区。
54 ## 命令行使用方式（个人开发助手模式）
55 
56 你可以通过以下两种方式从命令行运行WorkflowEngine：
57 
58 ### 使用安装后的CLI命令
59 
60 ```bash
61 bella-issues-bot --issue-id 42 --requirement "创建一个README文件"
62 ```
63 
64 ### 直接使用Python模块
65 
66 ```bash
67 python -m client.terminal --issue-id 42 --requirement "创建一个README文件"
68 ```
69 
70 ### 命令行参数
71 
72 #### 基础参数
73 
74 - `--issue-id -i`：（必需）问题ID，用于跟踪和引用
75 - `--requirement -r` 或 `--requirement-file -f`：（必需）具体需求描述或包含需求的文件路径
76 - `--project-dir -p`：项目目录路径（默认：当前目录）
77 
78 #### AI模型配置
79 
80 - `-model -m`： 同时配置核心模型和数据模型
81 - `-temperature -t`： 同时配置核心模型和数据模型温度
82 - `--core-model --cm`：核心AI操作使用的模型（默认：gpt-4o）
83 - `--data-model --dm`：数据操作使用的模型（默认：gpt-4o）
84 - `--core-temperature --ct`：核心模型的温度参数（默认：0.7）
85 - `--data-temperature --dt`：数据模型的温度参数（默认：0.7）
86 
87 #### 工作流配置
88 
89 - `--mode`：工作模式，可选"client"或"bot"（默认：client）
90   - `client`：个人开发助手模式，基于当前代码状态工作
91   - `bot`：GitHub自动化模式，拉取最新分支，自动提交并回复Issues
92 - `--default-branch --branch`：默认Git分支（默认：main）
93 - `--base-url -u`：API调用的基础URL
94 - `--api-key -k`：API密钥（也可以通过OPENAI_API_KEY环境变量设置）
95 - `--github-remote-url --git-url`：GitHub远程URL
96 - `--github-token --git-token`：GitHub令牌
97 
98 #### 执行控制
99 
100 - `--max-retry`：最大重试次数（默认：3）
101 
102 ### 简易脚本使用
103 
104 你也可以使用提供的脚本简化命令行调用：
105 
106 ```bash
107 ./scripts/run_bot.sh <问题ID> [需求文件路径]
108 ```
109 
110 ## 编程方式使用
111 
112 你也可以在Python代码中以编程方式使用客户端包：
113 
114 ```python
115 from client.runner import run_workflow
116 
117 run_workflow(
118     issue_id=42,
119     requirement="为项目创建一个README文件",
120     core_model="gpt-4o",
121     data_model="gpt-4o",
122     core_temperature=0.7,
123     data_temperature=0.7
124 )
125 ```
126 
127 ## 环境变量
128 
129 工具会读取以下环境变量：
130 
131 - `OPENAI_API_KEY`：OpenAI的API密钥
132 - `OPENAI_API_BASE`：OpenAI API的基础URL
133 - `GITHUB_TOKEN`：GitHub身份验证令牌
```




```
File: client/README_FILE_MEMORY.md
1 # FileMemory 客户端
2 
3 FileMemory 是 bella-issues-bot 的强大记忆系统组件之一，负责维护项目中所有文件的功能描述。通过 FileMemory，系统能够了解项目的整体结构和每个文件的作用，从而在处理用户需求时提供更加上下文相关的代码生成和修改。
4 
5 ## 特点与优势
6 
7 - **文件功能描述**：自动分析并生成项目中每个文件的功能描述
8 - **智能增量更新**：只为新增和变更的文件生成描述，提高效率
9 - **Git 集成**：使用 Git 历史记录追踪文件变更
10 - **独立运行**：可以独立于主工作流运行，专注于文件记忆维护
11 - **批量处理**：智能地将文件分批处理，可处理大型项目
12 - **失败重试**：提供对失败文件的重试机制
13 
14 ## 安装
15 
16 FileMemory 客户端作为 bella-issues-bot 的一部分安装:
17 
18 
19
```




```
File: client/README_GITHUB_WORKFLOWS.md
1 # GitHub工作流生成器
2 
3 bella-issues-bot 提供了自动生成 GitHub Actions 工作流配置的功能，可以轻松将 AI 助手集成到您的 GitHub 项目中。
4 
5 ## 功能概述
6 
7 工作流生成器会创建两个GitHub Actions工作流文件：
8 
9 1. **记忆初始化工作流** (`memory_init.yml`)
10    - 当指定分支有推送时触发
11    - 会跳过机器人自身的提交（通过检查提交信息中的"Update file memory"）
12    - 分析项目文件并生成文件描述
13    - 将记忆文件提交回仓库
14 
15 2. **Issue处理工作流** (`issue_process.yml`)
16    - 在创建新Issue或添加评论时触发
17    - 自动提取Issue或评论中的需求
18    - 在专用分支上处理需求并实现代码
19    - 创建拉取请求，提供解决方案
20    - 在Issue中添加处理结果的评论
21 
22 ## 命令行使用方式
23 
24 bella-github-workflows [选项]
25 
26 ### 记忆初始化工作流 (`memory_init.yml`)
27 
28 此工作流在指定分支有推送时运行，它：
29 1. 检查提交是否由自动化机器人产生（含有"Update file memory"的提交信息）
30    - 如果是机器人提交，则会跳过执行，防止无限循环
31    - 可以通过workflow_dispatch手动触发并强制执行
32 2. 检出代码库
33 3. 设置Python环境
34 4. 安装bella-issues-bot
35 5. 初始化文件记忆系统，生成项目文件描述
36 6. 将生成的记忆文件提交回仓库（提交信息带有[skip ci]标记）
37 
38 ### Issue处理工作流 (`issue_process.yml`)
39 
40 此工作流在创建新Issue或添加评论时运行，具体步骤如下：
41 1. 检出代码库
42 2. 设置Python环境
43 3. 安装bella-issues-bot
44 4. 提取Issue或评论中的需求
45 5. 运行bella-issues-bot处理需求（它会自动创建分支并提交代码）
46    - 如果评论以"bella-issues-bot已处理："开头，则跳过处理
47 6. 创建拉取请求
48 7. 在Issue中添加处理结果的评论
49 
50 ## GitHub配置要求
51
```




```
File: pyproject.toml
1 [tool.poetry]
2 name = "bella-issues-bot"
3 version = "0.1.1"
4 description = "bella-issues-bot 是一个基于人工智能的多功能代码开发助手，具备两种强大的工作模式：个人开发助手模式：在日常开发过程中，作为命令行工具辅助编码，帮助分析代码、生成实现、解决技术难题。GitHub自动化模式：集成到GitHub工作流中，自动监控和处理项目Issues，无需人工干预即可分析需求、提出解决方案并实现代码变更。"
5 authors = ["saizhuolin"]
6 license = "MIT"
7 readme = "README.md"
8 homepage = "https://github.com/szl97/bella-issues-bot"
9 repository = "https://github.com/szl97/bella-issues-bot"
10 documentation = "https://github.com/szl97/bella-issues-bot"
11 packages = [
12     {include = "core"},
13     {include = "client"}
14 ]
15 include = [
16     "system.txt"
17 ]
18 classifiers = [
19   "Development Status :: 4 - Beta",
20   "Topic :: Scientific/Engineering :: Artificial Intelligence",
21 ]
22 
23 [build-system]
24 requires = ["poetry-core>=1.0.0"]
25 build-backend = "poetry.core.masonry.api"
26 
27 [tool.poetry.dependencies]
28 python = ">=3.10,<3.13"
29 gitpython = "^3.1.40"
30 PyGithub = "^2.1.1"
31 langchain = ">=0.3.0,<0.4.0"
32 langchain-openai = ">=0.1.0"
33 langchain-core = ">=0.3.0,<0.4.0"
34 langchain-community = ">=0.3.0,<0.4.0"
35 python-dotenv = "^1.0.0"
36 pydantic = "^2.5.0"
37 openai = "^1.3.5"
38 pytest = "^7.4.0"
39 pathspec = ">=0.9.0"
40 toml = ">=0.10.2"
41 typing-extensions = ">=4.0.0"
42 jinja2 = ">=3.1.0,<4.0.0"
43 colorlog = ">=6.8.0,<7.0.0"
44 colorama = ">=0.4.4"
45 argparse = ">=1.4.0"
46 pyyaml = ">=6.0"
47 
48 [tool.poetry.scripts]
49 bella-issues-bot = 'client.terminal:run_workflow_from_terminal'
50 bella-file-memory = 'client.file_memory_client:main'
51 bella-github-workflows = 'client.github_workflow_generator:main'
52 
53 [tool.ruff]
54 select = ["F", "E", "W", "I001"]
55 show-fixes = false
56 target-version = "py310"
57 task-tags = ["TODO", "FIXME"]
58 extend-ignore = ["E501", "E722"]
59 
60 [tool.black]
61 target-version = ["py310"]
62 
63 [tool.ruff.isort]
64 known-first-party = []
65 known-third-party = []
66 section-order = [
67   "future",
68   "standard-library",
69   "third-party",
70   "first-party",
71   "local-folder",
72 ]
73 combine-as-imports = true
74 split-on-trailing-comma = false
75 lines-between-types = 1
76
```




```
File: core/workflow_engine.py
1 import os
2 import shutil
3 import tempfile
4 import uuid
5 from dataclasses import dataclass
6 from typing import Optional
7 
8 from core.ai import AIConfig
9 from core.chat_processor import ChatProcessor, ChatProcessorConfig
10 from core.code_engineer import CodeEngineer, CodeEngineerConfig
11 from core.decision import DecisionProcess
12 from core.diff import Diff
13 from core.file_memory import FileMemory, FileMemoryConfig
14 from core.file_selector import FileSelector
15 from core.git_manager import GitManager, GitConfig
16 from core.log_config import get_logger
17 from core.log_manager import LogManager, LogConfig
18 from core.prompt_generator import PromptGenerator, PromptData
19 from core.version_manager import VersionManager
20 
21 logger = get_logger(__name__)
22 
23 @dataclass
24 class WorkflowEngineConfig:
25     project_dir: str
26     issue_id:int
27     core_model:str = "gpt-4o"
28     data_model:str = "gpt-4o"
29     core_template: float = 0.7
30     data_template: float = 0.7
31     max_retry: int = 3,
32     default_branch: str = "main"
33     mode: str = "client" # ["client", "bot"] bot模式下，每次进行工作时，会hard reset到issues的最新分支上
34     base_url: Optional[str] = None
35     api_key: Optional[str] = None
36     github_remote_url: Optional[str] =None
37     github_token: Optional[str] = None
38 
39 
40 class WorkflowEngine:
41     CODE_TIMES = 0
42     CHAT_TIMES = 0
43     """
44     工作流引擎，协调版本管理、日志管理和AI交互
45     """
46     def __init__(self, config: WorkflowEngineConfig):
47         """
48         初始化工作流引擎
49         
50         Args:
51             config: 工作流配置
52         """
53         self.CODE_TIMES = 0
54         self.CHAT_TIMES = 0
55         # 存储原始配置
56         self.original_config = config
57         
58         # 根据模式设置工作目录
59         if config.mode == "bot":
60             # 创建临时目录作为工作区
61             self.temp_dir = os.path.join(
62                 tempfile.gettempdir(), 
63                 f"bella-bot-{config.issue_id}-{str(uuid.uuid4())[:8]}"
64             )
65             os.makedirs(self.temp_dir, exist_ok=True)
66             # 更新配置以使用临时目录
67             self.config = WorkflowEngineConfig(
68                 project_dir=self.temp_dir,
69                 **{k: v for k, v in vars(config).items() if k != 'project_dir'}
70             )
71             logger.info(f"Bot模式：创建临时工作目录 {self.temp_dir}")
72         else:
73             # 客户端模式直接使用指定的目录
74             self.config = config
75             self.temp_dir = None
76             logger.info("当前为client模式")
77 
78         self.project_dir = os.path.abspath(self.config.project_dir)
79         # 创建AI配置
80         self.core_ai_config = AIConfig(
81             model_name=config.core_model,
82             temperature=config.core_template,
83             base_url=config.base_url,
84             api_key=config.api_key
85         )
86         
87         self.data_ai_config = AIConfig(
88             model_name=config.data_model,
89             temperature=config.data_template,
90             base_url=config.base_url,
91             api_key=config.api_key
92         )
93         
94         # 创建Git配置
95         self.git_config = GitConfig(
96             repo_path=self.project_dir,
97             remote_url=config.github_remote_url or os.getenv("GIT_REMOTE"),
98             auth_token=config.github_token or os.getenv("GITHUB_TOKEN"),
99             default_branch=config.default_branch
100         )
101         
102         # 创建日志配置
103         self.log_config = LogConfig(
104             project_dir=self.project_dir,
105             issue_id=config.issue_id,
106             mode=config.mode
107         )
108         
109         # 初始化管理器
110         self.git_manager = GitManager(config=self.git_config)
111         self.log_manager = LogManager(config=self.log_config)
112         
113         # 初始化文件记忆管理，传入log_manager
114         self.file_memory = FileMemory(
115             config=FileMemoryConfig(
116                 git_manager=self.git_manager,
117                 ai_config=self.core_ai_config,
118                 project_dir=self.project_dir,
119                 log_manager=self.log_manager
120             )
121         )
122         self.version_manager = VersionManager(
123             issue_id=config.issue_id,
124             ai_config=self.core_ai_config,
125             log_manager=self.log_manager,
126             git_manager=self.git_manager,
127             file_memory=self.file_memory
128         )
129         self.file_selector = FileSelector(
130             self.project_dir,
131             self.config.issue_id,
132             ai_config=self.core_ai_config
133         )
134 
135         # 初始化代码工程师
136         self.code_engineer_config = CodeEngineerConfig(
137             project_dir=self.project_dir,
138             ai_config=self.core_ai_config
139         )
140         self.engineer = CodeEngineer(
141             self.code_engineer_config,
142             self.log_manager,
143             Diff(self.data_ai_config)
144         )
145         
146         # 初始化聊天处理器
147         self.chat_processor = ChatProcessor(
148             ai_config=self.core_ai_config,
149             log_manager=self.log_manager,
150             config=ChatProcessorConfig(system_prompt="你是一个项目助手，负责回答关于代码库的问题。下面会给出用户的问题以及相关的项目文件信息。")
151         )
152         
153         # 初始化决策环境
154         self.decision_env = DecisionProcess(
155             ai_config=self.core_ai_config,
156             version_manager=self.version_manager
157         )
158     
159     def process_requirement(self, user_requirement: str) -> Optional[str]:
160         """
161         处理用户需求
162         
163         Args:
164             user_requirement: 用户需求
165 
166         Returns:
167             str: 处理结果的响应文本
168         """
169         try:
170             # 初始化环境
171             self._setup_environment()
172             
173             response = self._process_requirement_internal(user_requirement)
174             
175             # 如果是bot模式，在结束时清理临时目录
176             if self.config.mode == "bot":
177                 self._cleanup_environment()
178             
179             return response
180         except Exception as e:
181             logger.error(f"处理需求时发生错误: {str(e)}")
182             raise
183 
184     def _setup_environment(self) -> None:
185         """
186         根据模式设置工作环境
187         """
188         if self.config.mode == "bot":
189             try:
190                 # 重置到issue对应的分支
191                 self.git_manager.reset_to_issue_branch(self.config.issue_id)
192                 logger.info(f"成功初始化Bot模式环境，工作目录: {self.temp_dir}")
193             except Exception as e:
194                 logger.error(f"初始化Bot模式环境失败: {str(e)}")
195                 self._cleanup_environment()
196                 raise
197         current_round = self.log_manager.get_current_round()
198 
199         # 如果轮次大于1，增量更新上一轮修改的文件详细信息
200         if self.file_memory and current_round > 1:
201             self.file_memory.update_file_details()
202             logger.info("已更新文件详细信息")
203         
204     def _cleanup_environment(self) -> None:
205         """
206         清理工作环境，删除临时目录
207         """
208         if self.config.mode == "bot" and self.temp_dir and os.path.exists(self.temp_dir):
209             try:
210                 # 关闭git仓库连接
211                 if hasattr(self, 'git_manager') and self.git_manager:
212                     self.git_manager.delete_local_repository()
213                 
214                 # 删除临时目录
215                 shutil.rmtree(self.temp_dir, ignore_errors=True)
216                 logger.info(f"已清理临时工作目录: {self.temp_dir}")
217             except Exception as e:
218                 logger.warning(f"清理临时目录时出错: {str(e)}")
219                 # 即使清理失败也不抛出异常，让主流程继续
220 
221     def _process_requirement_internal(self, user_requirement: str) -> Optional[str]:
222         """
223         内部处理需求的方法
224         
225         Args:
226             user_requirement: 用户需求
227             
228         Returns:
229             str: 处理结果
230         """
231         # 先通过决策环境分析需求类型
232         decision_result = self.decision_env.analyze_requirement(user_requirement)
233         
234         logger.info(f"决策结果: 是否需要修改代码={decision_result.needs_code_modification}, "
235                     f"理由={decision_result.reasoning}")
236         
237         if decision_result.needs_code_modification:
238             # 执行代码修改流程
239             response = self._run_code_generation_workflow(user_requirement)
240         else: 
241             # 执行对话流程
242             response = self._run_chat_workflow(user_requirement)
243         
244         # 如果是Bot模式且有GitHub配置，自动回复到issue
245         if self.config.mode == "bot":
246             try:
247                 self.version_manager.finalize_changes(mode=self.config.mode, comment_text=response)
248                 logger.info(f"更改已经推送到远端，并添加了Issue评论")
249             except Exception as e:
250                 logger.error(f"添加Issue评论时出错: {str(e)}")
251                 
252         return response
253     
254     def _run_code_generation_workflow(self, user_requirement: str) -> Optional[str]:
255         """
256         执行代码生成流程，基于example_code_generate.py的逻辑
257         
258         Args:
259             user_requirement: 用户需求
260             
261         Returns:
262             str: 处理结果
263         """
264         logger.info("开始执行代码生成流程")
265 
266         # 确定当前版本
267         requirement, history = self.version_manager.ensure_version_and_generate_context(user_requirement)
268 
269         # 生成提示词
270         user_prompt = self._get_user_prompt(requirement, history)
271 
272         # 根据提示词修改代码
273         success, response = self.engineer.process_prompt(prompt=user_prompt)
274 
275         # 提交更改
276         if success:
277             return response
278         else:
279             self.CODE_TIMES += 1
280             if self.CODE_TIMES >= self.config.max_retry:
281                 logger.error("code workflow超过最大重试次数")
282                 return self._run_chat_workflow(user_requirement)
283             else:
284                 return self._run_code_generation_workflow(user_requirement)
285     
286     def _run_chat_workflow(self, user_requirement: str) -> Optional[str]:
287         """
288         执行聊天流程，基于example_chat_process.py的逻辑
289         
290         Args:
291             user_requirement: 用户需求
292             
293         Returns:
294             str: 处理结果
295         """
296         logger.info("开始执行聊天回复流程")
297 
298         history = self.version_manager.get_formatted_history()
299 
300         # 生成提示词
301         user_prompt = self._get_user_prompt(user_requirement, history)
302         
303         # 处理聊天请求
304         response = self.chat_processor.process_chat(user_prompt)
305 
306         if(response):
307             return response
308         else:
309             self.CHAT_TIMES += 1
310             if self.CHAT_TIMES >= self.config.max_retry:
311                 logger.error("chat workflow超过最大重试次数")
312                 return None
313             else:
314                 return self._run_chat_workflow(user_requirement)
315 
316     def _get_user_prompt(self, requirement: str, history: str) -> str:
317         # 选择文件
318         files = self.file_selector.select_files_for_requirement(requirement)
319         descriptions = FileMemory.get_selected_file_descriptions(self.project_dir, files)
320 
321         # 准备提示词数据
322         data = PromptData(
323             requirement=requirement,
324             project_dir=self.project_dir,
325             steps=history,
326             files=files,
327             file_desc=descriptions
328         )
329 
330         # 生成提示词
331         return PromptGenerator.generatePrompt(data)
332
```




```
File: core/file_memory.py
1 import json
2 import os
3 import time
4 import datetime
5 from dataclasses import dataclass
6 from typing import Dict, List, Optional, Set, Union
7 
8 from dotenv import load_dotenv
9 from langchain.tools import Tool
10 
11 from core.ai import AIAssistant, AIConfig
12 from core.file_fetcher import FileFetcher
13 from core.git_manager import GitManager, GitConfig
14 from core.log_manager import LogManager
15 from core.log_config import get_logger
16 
17 logger = get_logger(__name__)
18 
19 @dataclass
20 class FileMemoryConfig:
21     """配置文件记忆管理"""
22     project_dir: str
23     git_manager: GitManager
24     ai_config: AIConfig
25     # 可选的LogManager，用于获取上一轮修改信息
26     log_manager: Optional[LogManager] = None
27 
28 
29 class FileDetail:
30     """文件详细信息类"""
31     pass
32 
33 
34 class FileMemory:
35     """管理文件描述的记忆"""
36 
37     MEMORY_DIR = ".eng/memory"
38     FILE_DETAILS_PATH = f"{MEMORY_DIR}/file_details.txt"
39     GIT_ID_FILE = f"{MEMORY_DIR}/git_id"
40     MAX_RETRIES = 3    # 最大重试次数
41     RETRY_DELAY = 30    # 重试延迟（秒）
42     # 每批次最大行数和字符数限制
43     MAX_LINES_PER_BATCH = 10000  # 最大行数
44     MAX_CHARS_PER_BATCH = 50000  # 最大字符数，约为 100KB
45     MAX_FILES_PER_BATCH = 20  # 每批次最多处理的文件数
46 
47     def __init__(self, config: FileMemoryConfig):
48         self.config = config
49         self.memory_path = os.path.join(config.project_dir, self.FILE_DETAILS_PATH)
50         self.git_id_path = os.path.join(config.project_dir, self.GIT_ID_FILE)
51 
52         # 保存LogManager引用
53         self.log_manager = config.log_manager
54 
55         # 初始化 AI 助手
56         self.ai_assistant = AIAssistant(config=self.config.ai_config, tools=[self._create_batch_description_tool()])
57 
58         # 初始化 Git 管理器
59         self.git_manager = self.config.git_manager
60 
61         # 确保内存目录存在
62         os.makedirs(os.path.dirname(self.memory_path), exist_ok=True)
63 
64     def _ensure_directories(self):
65         """确保必要的目录存在"""
66         memory_dir = os.path.join(self.config.project_dir, self.MEMORY_DIR)
67         os.makedirs(memory_dir, exist_ok=True)
68 
69     def _get_failed_files_path(self) -> str:
70         """获取失败文件记录的路径"""
71         return os.path.join(self.config.project_dir, self.MEMORY_DIR, "failed_files.json")
72 
73     def _read_failed_files(self) -> List[str]:
74         """读取处理失败的文件列表"""
75         failed_files_path = self._get_failed_files_path()
76         if os.path.exists(failed_files_path):
77             try:
78                 with open(failed_files_path, 'r', encoding='utf-8') as f:
79                     return json.load(f)
80             except Exception as e:
81                 logger.error(f"读取失败文件列表出错: {str(e)}")
82         return []
83 
84     def _write_failed_files(self, failed_files: List[str]) -> None:
85         """写入处理失败的文件列表"""
86         failed_files_path = self._get_failed_files_path()
87         try:
88             with open(failed_files_path, 'w', encoding='utf-8') as f:
89                 json.dump(failed_files, f, ensure_ascii=False, indent=2)
90         except Exception as e:
91             logger.error(f"写入失败文件列表出错: {str(e)}")
92 
93     def _create_batch_description_tool(self) -> Tool:
94         """创建批量生成文件描述的工具"""
95         from langchain.tools import Tool
96         
97         def process_file_descriptions(file_descriptions: str) -> Dict[str, str]:
98             """
99             处理文件描述列表
100             
101             Args:
102                 file_descriptions: JSON格式的文件描述列表，格式为 [{"fileName": "path/to/file.py", "desc": "文件描述"}]
103                 
104             Returns:
105                 Dict[str, str]: 文件路径到描述的映射
106             """
107             try:
108                 descriptions = {}
109                 file_list = json.loads(file_descriptions)
110                 
111                 if not isinstance(file_list, list):
112                     logger.error("错误：输入必须是一个列表")
113                     return descriptions
114                 
115                 # 处理结果
116                 for item in file_list:
117                     if isinstance(item, dict) and "fileName" in item and "desc" in item:
118                         descriptions[item["fileName"]] = item["desc"]
119                     else:
120                         logger.warning(f"跳过无效的文件描述项: {item}")
121                 
122                 logger.info(f"成功处理了 {len(descriptions)} 个文件描述")
123                 return descriptions
124             except json.JSONDecodeError:
125                 logger.error("错误：输入不是有效的 JSON 格式")
126                 return {}
127             except Exception as e:
128                 logger.error(f"处理文件描述时出错: {str(e)}")
129                 return {}
130         
131         return Tool(
132             name="process_file_descriptions",
133             description="处理文件描述列表，输入必须是JSON格式的列表，每个元素包含fileName和desc字段",
134             func=process_file_descriptions,
135             return_direct=True
136         )
137 
138     def _generate_batch_file_descriptions(self, files_with_content: List[Dict[str, str]]) -> Dict[str, str]:
139         """
140         批量生成文件描述
141         
142         Args:
143             files_with_content: 包含文件路径和内容的列表，格式为 [{"filepath": "path/to/file.py", "content": "..."}]
144             
145         Returns:
146             Dict[str, str]: 文件路径到描述的映射
147         """
148         # 构建提示词
149         files_text = ""
150         for i, file_info in enumerate(files_with_content):
151             files_text += f"\n--- 文件 {i+1}: {file_info['filepath']} ---\n{file_info['content']}\n"
152         
153         prompt = f"""
154 请分析以下多个代码文件，并为每个文件生成一个简短的中文描述（每个不超过100字）。
155 描述应该包含：
156 1. 文件的主要功能
157 2. 包含的关键类或函数
158 3. 与其他文件的主要交互（如果明显的话）
159 
160 {files_text}
161 
162 请使用process_file_descriptions工具返回结果，输入必须是一个JSON格式的列表，每个元素包含fileName和desc字段。
163 例如：
164 [
165   {{"fileName": "path/to/file1.py", "desc": "这个文件实现了..."}},
166   {{"fileName": "path/to/file2.py", "desc": "这个文件定义了..."}}
167 ]
168 
169 请确保每个文件都有对应的描述，并且描述准确反映文件的功能和内容。
170 """
171         
172         # 尝试生成描述，最多重试MAX_RETRIES次
173         descriptions = {}
174         failed_files = []
175         file_paths = [file_info["filepath"] for file_info in files_with_content]
176         
177         for attempt in range(self.MAX_RETRIES):
178             try:
179                 logger.info(f"尝试批量生成文件描述（第{attempt+1}次尝试）")
180                 
181                 # 使用工具生成描述
182                 descriptions = self.ai_assistant.generate_response(prompt, use_tools=True)
183                 
184                 # 如果返回的不是字典，可能是字符串响应
185                 if not isinstance(descriptions, dict):
186                     logger.error(f"工具返回了非预期的结果类型: {type(descriptions)}")
187                     descriptions = {}
188                 
189                 # 检查是否所有文件都有描述
190                 missing_files = [
191                     file_path for file_path in file_paths
192                     if file_path not in descriptions
193                 ]
194                 
195                 if missing_files:
196                     failed_files.extend(missing_files)
197                     logger.warning(f"以下文件未能生成描述: {missing_files}")
198                 
199                 # 如果有成功处理的文件，则返回结果
200                 if descriptions:
201                     return descriptions
202             
203             except Exception as e:
204                 logger.error(f"批量生成文件描述失败（第{attempt+1}次尝试）: {str(e)}")
205             
206             # 如果不是最后一次尝试，则等待后重试
207             if attempt < self.MAX_RETRIES - 1:
208                 logger.info(f"等待 {self.RETRY_DELAY} 秒后重试...")
209                 time.sleep(self.RETRY_DELAY)
210         
211         # 所有尝试都失败，记录失败的文件
212         self._update_failed_files(file_paths)
213         
214         # 返回空结果
215         return descriptions
216 
217     def _update_failed_files(self, new_failed_files: List[str]) -> None:
218         """更新失败文件列表"""
219         if not new_failed_files:
220             return
221             
222         # 读取现有失败文件列表
223         existing_failed_files = self._read_failed_files()
224         
225         # 合并并去重
226         all_failed_files = list(set(existing_failed_files + new_failed_files))
227         
228         # 写入更新后的列表
229         self._write_failed_files(all_failed_files)
230         logger.info(f"更新了失败文件列表，共 {len(all_failed_files)} 个文件")
231 
232     def process_failed_files(self) -> Dict[str, str]:
233         """处理之前失败的文件"""
234         failed_files = self._read_failed_files()
235         if not failed_files:
236             logger.info("没有需要处理的失败文件")
237             return {}
238             
239         logger.info(f"开始处理 {len(failed_files)} 个失败文件")
240         
241         # 准备文件内容
242         files_with_content = []
243         for filepath in failed_files:
244             content = self._get_file_content(filepath)
245             if content.strip():  # 跳过空文件
246                 files_with_content.append({"filepath": filepath, "content": content})
247         
248         # 按批次处理文件
249         descriptions = self._process_files_in_batches(files_with_content)
250         
251         # 更新失败文件列表
252         if descriptions:
253             # 找出成功处理的文件
254             processed_files = list(descriptions.keys())
255             # 更新失败文件列表
256             new_failed_files = [f for f in failed_files if f not in processed_files]
257             self._write_failed_files(new_failed_files)
258             
259             logger.info(f"成功处理了 {len(processed_files)} 个之前失败的文件，还有 {len(new_failed_files)} 个文件失败, 如果存在要忽略的文件，请在项目根目录下配置 .eng/.engignore 配置方式同.gitignore")
260         
261         return descriptions
262 
263 
264     def _get_file_content(self, filepath: str) -> str:
265         """获取文件内容"""
266         try:
267             full_path = os.path.join(self.config.project_dir, filepath)
268             with open(full_path, "r", encoding="utf-8") as f:
269                 return f.read()
270         except Exception as e:
271             logger.error(f"读取文件 {filepath} 失败: {str(e)}, 如果要忽略该文件，请在项目根目录下配置 .eng/.engignore 配置方式同.gitignore")
272             return ""
273 
274     def _process_files_in_batches(self, files_with_content: List[Dict[str, str]]) -> Dict[str, str]:
275         """将文件分批处理"""
276         all_descriptions = {}
277         current_batch = []
278         current_lines = 0
279         current_size = 0
280 
281         
282         for file_info in files_with_content:
283             content = file_info["content"]
284             lines = len(content.splitlines())
285             chars = len(content)
286             
287             if lines == 0:
288                 continue
289                 
290             # 检查是否需要开始新批次
291             # 如果当前批次已满或添加此文件会超出限制，则处理当前批次并开始新批次
292             if (current_batch and (
293                 len(current_batch) >= self.MAX_FILES_PER_BATCH or
294                 current_lines + lines > self.MAX_LINES_PER_BATCH or
295                 current_size + chars > self.MAX_CHARS_PER_BATCH
296             )):
297                 # 处理当前批次
298                 logger.info(f"处理批次: {len(current_batch)} 个文件，共 {current_lines} 行，{current_size} 字符")
299                 batch_descriptions = self._generate_batch_file_descriptions(current_batch)
300                 all_descriptions.update(batch_descriptions)
301                 
302                 # 重置批次
303                 current_batch = [file_info]
304                 current_lines = lines
305                 current_size = chars
306             else:
307                 current_batch.append(file_info)
308                 current_lines += lines
309                 current_size += chars
310         
311         # 处理最后一个批次
312         if current_batch:
313             logger.info(f"处理最后一个批次: {len(current_batch)} 个文件，共 {current_lines} 行，{current_size} 字符")
314             batch_descriptions = self._generate_batch_file_descriptions(current_batch)
315             all_descriptions.update(batch_descriptions)
316         
317         return all_descriptions
318 
319     def _process_files_chunk(self, files: List[str]) -> Dict[str, str]:
320         """处理一组文件，生成描述"""
321         # 准备文件内容
322         files_with_content = []
323         for filepath in files:
324             content = self._get_file_content(filepath)
325             if content.strip():  # 跳过空文件
326                 files_with_content.append({"filepath": filepath, "content": content})
327         
328         # 按批次处理文件
329         return self._process_files_in_batches(files_with_content)
330 
331     def _read_git_id(self) -> str:
332         """读取保存的 Git ID"""
333         if not os.path.exists(self.git_id_path):
334             return ""
335         with open(self.git_id_path, "r") as f:
336             return f.read().strip()
337 
338     def _write_git_id(self, git_id: str) -> None:
339         """写入当前 Git ID"""
340         with open(self.git_id_path, "w") as f:
341             f.write(git_id)
342 
343     def _read_file_details(self) -> Dict[str, str]:
344         """读取文件描述信息"""
345         if not os.path.exists(self.memory_path):
346             return {}
347 
348         details = {}
349         with open(self.memory_path, "r", encoding="utf-8") as f:
350             for line in f:
351                 if ":" in line:
352                     filename, description = line.strip().split(":", 1)
353                     details[filename] = description
354         return details
355 
356     def _write_file_details(self, details: Dict[str, str]) -> None:
357         """写入文件描述信息"""
358         with open(self.memory_path, "w", encoding="utf-8") as f:
359             for filename, description in sorted(details.items()):
360                 f.write(f"{filename}:{description}\n")
361 
362     def update_file_details(self) -> None:
363         """更新文件描述信息"""
364         # 获取所有文件
365         all_files = set(FileFetcher.get_all_files_without_ignore(self.config.project_dir))
366         
367         # 读取现有描述
368         existing_details = self._read_file_details()
369         
370         files_to_process = []
371         
372         # 如果有LogManager，使用它获取上一轮修改的文件
373         if self.log_manager:
374             # 获取上一轮修改的文件
375             log_modified_files = self._get_last_round_modified_files()
376             
377             # 只处理LogManager中标记为修改的文件
378             files_to_process = list(log_modified_files & all_files)
379             
380             # 删除不存在的文件的描述
381             existing_details = {
382                 k: v for k, v in existing_details.items() if k in all_files
383             }
384             
385             logger.info(f"使用LogManager方式更新文件描述，处理{len(files_to_process)}个修改的文件")
386         else:
387             # 如果没有LogManager，回退到Git方式
388             current_git_id = self.git_manager.get_current_commit_id()
389             saved_git_id = self._read_git_id()
390             files_to_process = self._get_changed_files_git(all_files, existing_details, current_git_id, saved_git_id)
391             logger.info(f"使用Git方式更新文件描述，处理{len(files_to_process)}个文件")
392 
393         # 处理需要更新的文件
394         if files_to_process:
395             new_descriptions = self._process_files_chunk(files_to_process)
396             existing_details.update(new_descriptions)
397 
398         # 保存结果
399         self._write_file_details(existing_details)
400         if not self.log_manager:
401             # 只有使用Git方式时才更新Git ID
402             current_git_id = self.git_manager.get_current_commit_id()
403             self._write_git_id(current_git_id)
404 
405     def _get_last_round_modified_files(self) -> set:
406         """
407         从LogManager获取上一轮修改的文件列表
408         
409         Returns:
410             set: 上一轮修改的文件路径集合
411         """
412         if not self.log_manager:
413             logger.info("未提供LogManager，无法获取上一轮修改的文件")
414             return set()
415         
416         try:
417             # 获取当前轮次
418             current_round = self.log_manager.get_current_round()
419             
420             # 获取上一轮的日志条目
421             if current_round > 1:
422                 prev_round = current_round - 1
423                 log_entry = self.log_manager.get_issue_round_log_entry(prev_round, include_diff=True)
424                 
425                 if log_entry and log_entry.modified_files:
426                     # 从diff_info中提取文件路径
427                     modified_files = set()
428                     for diff_info in log_entry.modified_files:
429                         if diff_info.file_name and diff_info.is_create:
430                             modified_files.add(diff_info.file_name)
431                     
432                     logger.info(f"从LogManager获取到上一轮({prev_round})修改的文件: {len(modified_files)}个")
433                     return modified_files
434             return set()
435         except Exception as e:
436             logger.error(f"获取上一轮修改的文件失败: {str(e)}")
437             return set()
438 
439     def _get_changed_files_git(self, all_files: Set[str], existing_details: Dict[str, str], 
440                              current_git_id: str, saved_git_id: Optional[str]) -> List[str]:
441         """使用Git方式获取需要处理的文件列表"""
442         if saved_git_id:
443             # 获取自上次运行以来修改的文件
444             changed_files = set(
445                 self.git_manager.get_changed_files(saved_git_id, current_git_id)
446             ) & all_files
447             
448             logger.info(f"从Git获取到变更文件: {len(changed_files)}个")
449             
450             new_files = all_files - set(existing_details.keys())
451             logger.info(f"检测到新文件: {len(new_files)}个")
452             
453             return list(changed_files | new_files)
454         else:
455             # 首次运行，处理所有文件
456             return list(all_files)
457 
458     @classmethod
459     def get_file_descriptions(cls, project_dir: str) -> Dict[str, str]:
460         """获取文件描述的静态方法"""
461         memory_path = os.path.join(project_dir, cls.FILE_DETAILS_PATH)
462 
463         if not os.path.exists(memory_path):
464             return {}
465 
466         try:
467             descriptions = {}
468             with open(memory_path, "r", encoding="utf-8") as f:
469                 for line in f:
470                     if ":" in line:
471                         filename, description = line.strip().split(":", 1)
472                         descriptions[filename] = description
473             return descriptions
474         except Exception as e:
475             logger.error(f"读取文件描述失败: {str(e)}")
476             return {}
477 
478     @classmethod
479     def get_selected_file_descriptions(cls, project_dir: str, files: List[str]) -> Dict[str, str]:
480         """获取文件描述的静态方法"""
481         memory_path = os.path.join(project_dir, cls.FILE_DETAILS_PATH)
482 
483         if not os.path.exists(memory_path):
484             return {}
485         try:
486             descriptions = {}
487             with open(memory_path, "r", encoding="utf-8") as f:
488                 for line in f:
489                     if ":" in line:
490                         filename, description = line.strip().split(":", 1)
491                         if filename in files:
492                             descriptions[filename] = description
493             return descriptions
494         except Exception as e:
495             logger.error(f"读取文件描述失败: {str(e)}")
496             return {}
497 
498 if __name__ == "__main__":
499     load_dotenv()
500     project_dir = "../."
501     memory = FileMemory(
502         FileMemoryConfig(
503             ai_config=AIConfig(temperature=1, model_name="claude-3.7-sonnet"),
504             git_manager=GitManager(config=GitConfig(repo_path=project_dir)),
505             log_manager=None
506         )
507     )
508 
509     memory.update_file_details()
510
```




```
File: client/github_workflow_generator.py
1 """
2 GitHub Workflow Generator
3 
4 A module for generating GitHub Actions workflow files to integrate bella-issues-bot with GitHub.
5 Creates two workflows:
6 1. File Memory Initialization - Triggered on push to a configurable branch
7 2. Issue Processing Bot - Triggered when issues are created or commented on
8 """
9 
10 import argparse
11 import os
12 import sys
13 from pathlib import Path
14 from typing import Dict, Optional
15 
16 from core.log_config import get_logger, setup_logging
17 
18 logger = get_logger(__name__)
19 
20 # Template for memory initialization workflow
21 MEMORY_INIT_TEMPLATE = """name: Initialize File Memory
22 
23 on:
24   workflow_dispatch:  # Allow manual triggering
25     inputs:
26       force_run:
27         description: 'Force execution even for automated commits'
28   push:
29     branches:
30       - {branch}
31 
32 jobs:
33   init-memory:
34     runs-on: ubuntu-latest
35     permissions:
36       contents: write
37     steps:
38       - name: Checkout code
39         uses: actions/checkout@v3
40         with:
41           fetch-depth: 0
42           
43       - name: Check if commit is from automation
44         id: check_commit
45         run: |
46           COMMIT_MSG=$(git log -1 --pretty=format:"%s")
47           echo "is_bot_commit=$(echo $COMMIT_MSG | grep -q 'Update file memory [skip ci]' && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
48 
49       - name: Set up Python
50         uses: actions/setup-python@v4
51         with:
52           python-version: '3.10'
53 
54       - name: Install bella-issues-bot
55         run: |
56           python -m pip install --upgrade pip
57           pip install bella-issues-bot{package_version}
58 
59       - name: Initialize file memory
60         if: ${{{{ (github.event_name == 'workflow_dispatch' && github.event.inputs.force_run == 'true') || (steps.check_commit.outputs.is_bot_commit == 'false') }}}}
61         env:
62           OPENAI_API_KEY: ${{{{ secrets.OPENAI_API_KEY }}}}
63           OPENAI_API_BASE: ${{{{ secrets.OPENAI_API_BASE }}}}
64           GIT_REMOTE: ${{{{ github.server_url }}}}/${{{{ github.repository }}}}
65           GITHUB_TOKEN: ${{{{ secrets.GITHUB_TOKEN }}}}
66         run: |
67           bella-file-memory -d . -m {model} -t {temperature}
68 
69       - name: Commit memory files if changed
70         if: ${{{{ (github.event_name == 'workflow_dispatch' && github.event.inputs.force_run == 'true') || (steps.check_commit.outputs.is_bot_commit == 'false') }}}}
71         run: |
72           git config --local user.email "action@github.com"
73           git config --local user.name "GitHub Action"
74           git add .eng/memory/
75           git diff --staged --quiet || git commit -m "Update file memory [skip ci]"
76           git push
77 """
78 
79 # Template for issue processing workflow
80 ISSUE_PROCESS_TEMPLATE = """name: Process Issues with bella-issues-bot
81 
82 on:
83   issues:
84     types: [opened]
85   issue_comment:
86     types: [created]
87 
88 jobs:
89   process-issue:
90     runs-on: ubuntu-latest
91     permissions:
92       contents: write
93       issues: write
94     if: ${{{{ github.event_name == 'issues' || !startsWith(github.event.comment.body, 'bella-issues-bot已处理：') }}}}
95     steps:
96       - name: Checkout code
97         uses: actions/checkout@v3
98         with:
99           fetch-depth: 0
100 
101       - name: Set up Python
102         uses: actions/setup-python@v4
103         with:
104           python-version: '3.10'
105 
106       - name: Install bella-issues-bot
107         run: |
108           python -m pip install --upgrade pip
109           pip install bella-issues-bot{package_version}
110 
111       - name: Extract issue info
112         id: issue
113         run: |
114           if [[ "${{{{ github.event_name }}}}" == "issues" ]]; then
115             echo "issue_id=${{{{ github.event.issue.number }}}}" >> $GITHUB_OUTPUT
116             echo "requirement<<EOF" >> $GITHUB_OUTPUT
117             echo "${{{{ github.event.issue.body }}}}" >> $GITHUB_OUTPUT
118             echo "EOF" >> $GITHUB_OUTPUT
119           else
120             echo "issue_id=${{{{ github.event.issue.number }}}}" >> $GITHUB_OUTPUT
121             echo "requirement<<EOF" >> $GITHUB_OUTPUT
122             echo "${{{{ github.event.comment.body }}}}" >> $GITHUB_OUTPUT
123             echo "EOF" >> $GITHUB_OUTPUT
124           fi
125 
126       - name: Process issue with bella-issues-bot
127         env:
128           OPENAI_API_KEY: ${{{{ secrets.OPENAI_API_KEY }}}}
129           OPENAI_API_BASE: ${{{{ secrets.OPENAI_API_BASE }}}}
130           GIT_REMOTE: ${{{{ github.server_url }}}}/${{{{ github.repository }}}}
131           GITHUB_TOKEN: ${{{{ secrets.GITHUB_TOKEN }}}}
132           ISSUE_ID: ${{{{ steps.issue.outputs.issue_id }}}}
133         run: |
134           # Run bella-issues-bot in bot mode - it will handle branch creation and pushing
135           bella-issues-bot --mode bot --issue-id ${{{{ steps.issue.outputs.issue_id }}}} --core-model {core_model} --data-model {data_model} --core-temperature {core_temperature} --data-temperature {data_temperature} --requirement "${{{{ steps.issue.outputs.requirement }}}}"
136 """
137 
138 def generate_workflow_files(
139     output_dir: str,
140     base_branch: str = "main",
141     model: str = "gpt-4o",
142     core_model: Optional[str] = None,
143     data_model: Optional[str] = None,
144     temperature: float = 0.7,
145     core_temperature: Optional[float] = None,
146     data_temperature: Optional[float] = None,
147     package_version: str = ""
148 ) -> Dict[str, str]:
149     """
150     Generate GitHub workflow YAML files.
151     
152     Args:
153         output_dir: Directory to write workflow files
154         base_branch: Base branch for pull requests
155         model: Default model to use for all operations
156         core_model: Model for core operations (if different from model)
157         data_model: Model for data operations (if different from model)
158         temperature: Default temperature setting for all models
159         core_temperature: Temperature for core model (if different)
160         data_temperature: Temperature for data model (if different)
161         package_version: Specific version of package to install (e.g. "==0.1.1")
162         
163     Returns:
164         Dictionary mapping file paths to their contents
165     """
166     workflows_dir = os.path.join(output_dir, ".github", "workflows")
167     os.makedirs(workflows_dir, exist_ok=True)
168     
169     # Format version specification if provided
170     if package_version and not package_version.startswith("=="):
171         package_version = f"=={package_version}"
172     
173     # Use provided models or default to the general model
174     actual_core_model = core_model or model
175     actual_data_model = data_model or model
176     
177     # Use provided temperatures or default to the general temperature
178     actual_core_temp = core_temperature if core_temperature is not None else temperature
179     actual_data_temp = data_temperature if data_temperature is not None else temperature
180     
181     # Generate memory initialization workflow
182     memory_workflow_path = os.path.join(workflows_dir, "memory_init.yml")
183     memory_workflow_content = MEMORY_INIT_TEMPLATE.format(
184         branch=base_branch,
185         model=model,
186         temperature=temperature,
187         package_version=package_version
188     )
189     
190     # Generate issue processing workflow
191     issue_workflow_path = os.path.join(workflows_dir, "issue_process.yml")
192     issue_workflow_content = ISSUE_PROCESS_TEMPLATE.format(
193         core_model=actual_core_model,
194         data_model=actual_data_model,
195         core_temperature=actual_core_temp,
196         data_temperature=actual_data_temp,
197         base_branch=base_branch,
198         package_version=package_version
199     )
200     
201     # Write the files
202     with open(memory_workflow_path, 'w') as f:
203         f.write(memory_workflow_content)
204     
205     with open(issue_workflow_path, 'w') as f:
206         f.write(issue_workflow_content)
207     
208     logger.info(f"Generated workflow files in {workflows_dir}")
209     
210     return {
211         memory_workflow_path: memory_workflow_content,
212         issue_workflow_path: issue_workflow_content
213     }
214 
215 def main() -> None:
216     """Command line interface for GitHub workflow generator."""
217     parser = argparse.ArgumentParser(description="Generate GitHub Actions workflows for bella-issues-bot integration")
218     parser.add_argument("--output", "-o", type=str, default=".", help="Output directory (default: current directory)")
219     parser.add_argument("--base-branch", "-b", type=str, default="main", help="Base branch for pull requests (default: main)")
220     parser.add_argument("--model", "-m", type=str, default="gpt-4o", help="Default model for all operations (default: gpt-4o)")
221     parser.add_argument("--core-model", "--cm", type=str, help="Model for core operations (defaults to --model)")
222     parser.add_argument("--data-model", "--dm", type=str, help="Model for data operations (defaults to --model)")
223     parser.add_argument("--temperature", "-t", type=float, default=0.7, help="Default temperature for all models (default: 0.7)")
224     parser.add_argument("--core-temperature", "--ct", type=float, help="Temperature for core model (defaults to --temperature)")
225     parser.add_argument("--data-temperature", "--dt", type=float, help="Temperature for data model (defaults to --temperature)")
226     parser.add_argument("--package-version", "-v", type=str, default="", help="Specific package version to install (e.g. '0.1.1')")
227     parser.add_argument("--log-level", "-l", type=str, choices=["DEBUG", "INFO", "WARNING", "ERROR"], default="INFO", help="Logging level")
228     
229     args = parser.parse_args()
230     
231     # Setup logging
232     import logging
233     setup_logging(log_level=getattr(logging, args.log_level))
234     
235     # Generate workflow files
236     try:
237         generate_workflow_files(
238             output_dir=args.output,
239             base_branch=args.base_branch,
240             model=args.model,
241             core_model=args.core_model,
242             data_model=args.data_model,
243             temperature=args.temperature,
244             core_temperature=args.core_temperature,
245             data_temperature=args.data_temperature,
246             package_version=args.package_version
247         )
248         logger.info("Successfully generated GitHub workflow files")
249     except Exception as e:
250         logger.error(f"Error generating workflow files: {str(e)}")
251         sys.exit(1)
252 
253 if __name__ == "__main__":
254     main()
255
```




```
File: client/file_memory_client.py
1 """
2 File Memory Client
3 
4 A standalone client for initializing and managing FileMemory using only GitManager.
5 This module provides both CLI and programmatic interfaces for updating file descriptions.
6 """
7 
8 import argparse
9 import logging
10 import os
11 import shutil
12 import sys
13 import tempfile
14 import uuid
15 from typing import Dict, List, Optional
16 
17 from dotenv import load_dotenv
18 
19 from core.ai import AIConfig
20 from core.file_memory import FileMemory, FileMemoryConfig
21 from core.git_manager import GitManager, GitConfig
22 from core.log_config import setup_logging, get_logger
23 
24 logger = get_logger(__name__)
25 
26 
27 def initialize_file_memory(
28     project_dir: str,
29     model_name: str = "gpt-4o",
30     temperature: float = 0.7,
31     api_key: Optional[str] = None,
32     base_url: Optional[str] = None,
33     remote_url: Optional[str] = None,
34     auth_token: Optional[str] = None,
35 ) -> FileMemory:
36     """
37     Initialize FileMemory using GitManager without LogManager.
38     
39     Args:
40         project_dir: Path to the project directory
41         model_name: AI model to use for generating file descriptions
42         temperature: Temperature setting for AI responses
43         api_key: API key for AI service (will use env var if None)
44         base_url: Base URL for AI service (will use default if None)
45         remote_url: Git remote URL (will use env var if None)
46         auth_token: Git authentication token (will use env var if None)
47         
48     Returns:
49         Initialized FileMemory instance
50     """
51     # Create AI config
52     ai_config = AIConfig(
53         model_name=model_name,
54         temperature=temperature,
55         api_key=api_key,
56         base_url=base_url
57     )
58     
59     # Create Git config
60     git_config = GitConfig(
61         repo_path=project_dir,
62         remote_url=remote_url or os.getenv("GIT_REMOTE_URL"),
63         auth_token=auth_token or os.getenv("GITHUB_TOKEN")
64     )
65     
66     # Initialize Git manager
67     git_manager = GitManager(config=git_config)
68     
69     # Initialize and return FileMemory
70     file_memory_config = FileMemoryConfig(
71         project_dir=project_dir,
72         git_manager=git_manager,
73         ai_config=ai_config,
74         log_manager=None  # Explicitly set to None as per requirements
75     )
76     
77     return FileMemory(config=file_memory_config)
78 
79 
80 def update_file_descriptions(file_memory: FileMemory) -> None:
81     """
82     Update file descriptions using the given FileMemory instance.
83     
84     Args:
85         file_memory: Initialized FileMemory instance
86         
87     Returns:
88         Dictionary mapping file paths to their descriptions
89     """
90     return file_memory.update_file_details()
91 
92 
93 def process_failed_files(file_memory: FileMemory) -> Dict[str, str]:
94     """
95     Process previously failed files to generate their descriptions.
96     
97     Args:
98         file_memory: Initialized FileMemory instance
99         
100     Returns:
101         Dictionary mapping file paths to their descriptions
102     """
103     return file_memory.process_failed_files()
104 
105 
106 def main() -> None:
107     """Command line interface for FileMemory client."""
108     # Load environment variables
109     load_dotenv()
110     
111     # Parse command line arguments
112     parser = argparse.ArgumentParser(description="FileMemory Client - Update file descriptions for a project")
113     parser.add_argument("-d", "--directory", default=".", help="Project directory path (default: current directory)")
114     parser.add_argument("-m", "--model", default="gpt-4o", help="AI model name (default: gpt-4o)")
115     parser.add_argument("-t", "--temperature", type=float, default=0.7, help="AI temperature (default: 0.7)")
116     parser.add_argument("-k", "--api-key", help="OpenAI API key (defaults to OPENAI_API_KEY env var)")
117     parser.add_argument("-u", "--base-url", help="Base URL for API calls (optional)")
118     parser.add_argument("--git-url", help="Git remote URL (defaults to GIT_REMOTE_URL env var)")
119     parser.add_argument("--git-token", help="Git auth token (defaults to GITHUB_TOKEN env var)")
120     parser.add_argument("-l", "--log-level", choices=["DEBUG", "INFO", "WARNING", "ERROR"], default="INFO", help="Logging level")
121     parser.add_argument("--failed-only", action="store_true", help="Process only previously failed files")
122     parser.add_argument("-md", "--mode", default="client", help="Project directory path (default: current directory)")
123     args = parser.parse_args()
124     
125     # Setup logging
126     setup_logging(log_level=getattr(logging, args.log_level))
127 
128     if args.mode == "bot":
129         project_dir = os.path.join(
130             tempfile.gettempdir(),
131             f"bella-bot-memory-init-{str(uuid.uuid4())[:8]}"
132         )
133     else:
134         # Get absolute path for project directory
135         project_dir = os.path.abspath(args.directory)
136         if not os.path.isdir(project_dir):
137             logger.error(f"Project directory does not exist: {project_dir}")
138             sys.exit(1)
139     
140     try:
141         # Initialize FileMemory
142         file_memory = initialize_file_memory(
143             project_dir=project_dir,
144             model_name=args.model,
145             temperature=args.temperature,
146             api_key=args.api_key,
147             base_url=args.base_url,
148             remote_url=args.git_url,
149             auth_token=args.git_token
150         )
151 
152 
153         # Update file details or process failed files
154         if args.failed_only:
155             process_failed_files(file_memory)
156             logger.info("Processed failed files")
157         else:
158             update_file_descriptions(file_memory)
159             logger.info("Updated descriptions files")
160 
161 
162         file_memory.git_manager.delete_local_repository()
163     finally:
164         if args.mode == "bot":
165             # 删除临时目录
166             shutil.rmtree(project_dir, ignore_errors=True)
167             logger.info(f"已清理临时工作目录: {project_dir}")
168 
169 
170 if __name__ == "__main__":
171     setup_logging()
172     main()
173
```




```
File: system.txt
1 You will get instructions for code to write.
2 You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.
3 Think step by step and reason yourself to the correct decisions to make sure we get it right.
4 Make changes to existing code and implement new code in the unified git diff syntax. When implementing new code, First lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.
5 
6 You will output the content of each file necessary to achieve the goal, including ALL code.
7 Output requested code changes and new code in the unified "git diff" syntax. Example:
8 
9 ```diff
10 --- example.txt
11 +++ example.txt
12 @@ -6,3 +6,4 @@
13      line content A
14      line content B
15 +    new line added
16 -    original line X
17 +    modified line X with changes
18 @@ -26,4 +27,5 @@
19          condition check:
20 -            action for condition A
21 +            if certain condition is met:
22 +                alternative action for condition A
23          another condition check:
24 -            action for condition B
25 +            modified action for condition B
26 ```
27 
28 Example of a git diff creating a new file:
29 
30 ```diff
31 --- /dev/null
32 +++ new_file.txt
33 @@ -0,0 +1,3 @@
34 +First example line
35 +
36 +Last example line
37 ```
38 
39 RULES:
40 -A program will apply the diffs you generate exactly to the code, so diffs must be precise and unambiguous!
41 -Every diff must be fenced with triple backtick ```.
42 -The file names at the beginning of a diff, (lines starting with --- and +++) is the relative path to the file before and after the diff.
43 -LINES TO BE REMOVED (starting with single -) AND LINES TO BE RETAIN (no starting symbol) HAVE TO REPLICATE THE DIFFED HUNK OF THE CODE EXACTLY LINE BY LINE. KEEP THE NUMBER OF RETAIN LINES SMALL IF POSSIBLE.
44 -EACH LINE IN THE SOURCE FILES STARTS WITH A LINE NUMBER, WHICH IS NOT PART OF THE SOURCE CODE. NEVER TRANSFER THESE LINE NUMBERS TO THE DIFF HUNKS.
45 -AVOID STARTING A HUNK WITH AN EMPTY LINE.
46 -ENSURE ALL CHANGES ARE PROVIDED IN A SINGLE DIFF CHUNK PER FILE TO PREVENT MULTIPLE DIFFS ON THE SAME FILE.
47 
48 
49 As far as compatible with the user request, start with the "entrypoint" file, then go to the ones that are imported by that file, and so on.
50 Please note that the code should be fully functional. No placeholders.
51 
52 Follow a language and framework appropriate best practice file naming convention.
53 Make sure that files contain all imports, types etc.  The code should be fully functional. Make sure that code in different files are compatible with each other.
54 Ensure to implement all code, if you are unsure, write a plausible implementation.
55 Include module dependency or package manager dependency definition file.
56 Before you finish, double check that all parts of the architecture is present in the files.
57 
58 When you are done, write finish with "this concludes a fully working implementation".
59 
60 Useful to know:
61 Almost always put different classes in different files.
62 Always use the programming language the user asks for.
63 For Python, you always create an appropriate requirements.txt file.
64 For NodeJS, you always create an appropriate package.json file.
65 Always add a comment briefly describing the purpose of the function definition.
66 Add comments explaining very complex bits of logic.
67 Always follow the best practices for the requested languages for folder/file structure and how to package the project.
68 
69 
70 Python toolbelt preferences:
71 - pytest
72 - dataclasses
```




# 用户需求


    分析项目的所有代码。把项目的Read.me进行完善。尤其是未完成的。
    