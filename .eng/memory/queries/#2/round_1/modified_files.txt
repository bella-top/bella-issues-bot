[
  {
    "file_name": "client/cli.py",
    "content": "diff\n--- client/cli.py\n+++ client/cli.py\n@@ -18,55 +18,82 @@\n     # Required arguments\n     parser.add_argument(\n         \"--project-dir\", \n+        \"-p\",\n         type=str, \n         default=os.path.abspath(os.getcwd()),\n         help=\"Path to the project directory (default: current directory)\"\n     )\n     parser.add_argument(\n         \"--issue-id\", \n+        \"-i\",\n         type=int, \n         required=True,\n         help=\"The ID of the issue being processed\"\n     )\n     parser.add_argument(\n         \"--requirement\", \n+        \"-r\",\n         type=str, \n         help=\"The user requirement text\"\n     )\n     parser.add_argument(\n         \"--requirement-file\", \n+        \"-f\",\n         type=str, \n         help=\"Path to file containing the user requirement\"\n     )\n \n     # Optional arguments for WorkflowEngineConfig\n+    # 统一模型配置\n+    parser.add_argument(\n+        \"--model\", \n+        \"-m\",\n+        type=str, \n+        help=\"Model to use for both core and data operations (优先级高于单独配置)\"\n+    )\n+    parser.add_argument(\n+        \"--temperature\", \n+        \"-t\",\n+        type=float, \n+        help=\"Temperature for both core and data models (优先级高于单独配置)\"\n+    )\n+    \n+    # 独立模型配置\n     parser.add_argument(\n         \"--core-model\", \n+        \"--cm\",\n         type=str, \n         default=\"gpt-4o\",\n-        help=\"Model to use for core AI operations\"\n+        help=\"Model to use for core AI operations (当未设置--model时使用)\"\n     )\n     parser.add_argument(\n         \"--data-model\", \n+        \"--dm\",\n         type=str, \n         default=\"gpt-4o\",\n-        help=\"Model to use for data operations\"\n+        help=\"Model to use for data operations (当未设置--model时使用)\"\n     )\n     parser.add_argument(\n         \"--core-temperature\", \n+        \"--ct\",\n         type=float, \n         default=0.7,\n-        help=\"Temperature for core model\"\n+        help=\"Temperature for core model (当未设置--temperature时使用)\"\n     )\n     parser.add_argument(\n         \"--data-temperature\", \n+        \"--dt\",\n         type=float, \n         default=0.7,\n-        help=\"Temperature for data model\"\n+        help=\"Temperature for data model (当未设置--temperature时使用)\"\n     )\n     parser.add_argument(\n         \"--max-retry\", \n+        \"--retry\",\n         type=int, \n         default=3,\n         help=\"Maximum number of retry attempts\"\n     )\n     parser.add_argument(\n         \"--default-branch\", \n+        \"--branch\",\n         type=str, \n         default=\"main\",\n         help=\"Default branch name\"\n@@ -79,6 +106,7 @@\n     parser.add_argument(\n         \"--mode\", \n         type=str, \n+        \"-md\",\n         choices=[\"client\", \"bot\"],\n         default=\"client\",\n         help=\"Operation mode: 'client' or 'bot'\"\n@@ -86,21 +114,25 @@\n     parser.add_argument(\n         \"--base-url\", \n         type=str, \n+        \"-u\",\n         help=\"Base URL for API calls\"\n     )\n     parser.add_argument(\n         \"--api-key\", \n         type=str, \n+        \"-k\",\n         help=\"API key for authentication\"\n     )\n     parser.add_argument(\n         \"--github-remote-url\", \n         type=str, \n+        \"--git-url\",\n         help=\"GitHub remote repository URL\"\n     )\n     parser.add_argument(\n         \"--github-token\", \n         type=str, \n+        \"--git-token\",\n         help=\"GitHub authentication token\"\n     )\n     \n@@ -125,14 +157,30 @@\n \n def build_config_from_args(args: argparse.Namespace) -> Dict[str, Any]:\n     \"\"\"Build WorkflowEngineConfig parameters from command line arguments.\"\"\"\n+    \n+    # 处理统一的模型和温度配置\n+    core_model = args.core_model\n+    data_model = args.data_model\n+    core_temperature = args.core_temperature\n+    data_temperature = args.data_temperature\n+    \n+    # 如果设置了统一模型，则覆盖个别设置\n+    if args.model:\n+        core_model = args.model\n+        data_model = args.model\n+        \n+    # 如果设置了统一温度，则覆盖个别设置\n+    if args.temperature is not None:\n+        core_temperature = args.temperature\n+        data_temperature = args.temperature\n+    \n     config_params = {\n         \"project_dir\": args.project_dir,\n         \"issue_id\": args.issue_id,\n-        \"core_model\": args.core_model,\n-        \"data_model\": args.data_model,\n-        \"core_template\": args.core_temperature,  # Note: using template to match original param name\n-        \"data_template\": args.data_temperature,  # Note: using template to match original param name\n-        \"max_retry\": args.max_retry,\n+        \"core_model\": core_model,\n+        \"data_model\": data_model,\n+        \"core_template\": core_temperature,  # Note: using template to match original param name\n+        \"data_template\": data_temperature,  # Note: using template to match original param name\n+        \"max_retry\": args.max_retry, \n         \"default_branch\": args.default_branch,\n         \"mode\": args.mode,\n     }\n\n",
    "file_content": "\"\"\"\nCommand-line interface for the WorkflowEngine.\nProvides functionality to parse command-line arguments and run the engine.\n\"\"\"\n\nimport argparse\nimport os\nimport sys\nfrom typing import Optional, Dict, Any\n\n\ndef parse_args() -> argparse.Namespace:\n    \"\"\"Parse command-line arguments for the WorkflowEngine.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Run the WorkflowEngine to process user requirements\"\n    )\n\n    # Required arguments\n    parser.add_argument(\n        \"--project-dir\", \n        type=str, \n        default=os.path.abspath(os.getcwd()),\n        help=\"Path to the project directory (default: current directory)\"\n    )\n    parser.add_argument(\n        \"--issue-id\", \n        type=int, \n        required=True,\n        help=\"The ID of the issue being processed\"\n    )\n    parser.add_argument(\n        \"--requirement\", \n        type=str, \n        help=\"The user requirement text\"\n    )\n    parser.add_argument(\n        \"--requirement-file\", \n        type=str, \n        help=\"Path to file containing the user requirement\"\n    )\n\n    # Optional arguments for WorkflowEngineConfig\n    parser.add_argument(\n        \"--core-model\", \n        type=str, \n        default=\"gpt-4o\",\n        help=\"Model to use for core AI operations\"\n    )\n    parser.add_argument(\n        \"--data-model\", \n        type=str, \n        default=\"gpt-4o\",\n        help=\"Model to use for data operations\"\n    )\n    parser.add_argument(\n        \"--core-temperature\", \n        type=float, \n        default=0.7,\n        help=\"Temperature for core model\"\n    )\n    parser.add_argument(\n        \"--data-temperature\", \n        type=float, \n        default=0.7,\n        help=\"Temperature for data model\"\n    )\n    parser.add_argument(\n        \"--max-retry\", \n        type=int, \n        default=3,\n        help=\"Maximum number of retry attempts\"\n    )\n    parser.add_argument(\n        \"--default-branch\", \n        type=str, \n        default=\"main\",\n        help=\"Default branch name\"\n    )\n    parser.add_argument(\n        \"--mode\", \n        type=str, \n        choices=[\"client\", \"bot\"],\n        default=\"client\",\n        help=\"Operation mode: 'client' or 'bot'\"\n    )\n    parser.add_argument(\n        \"--base-url\", \n        type=str, \n        help=\"Base URL for API calls\"\n    )\n    parser.add_argument(\n        \"--api-key\", \n        type=str, \n        help=\"API key for authentication\"\n    )\n    parser.add_argument(\n        \"--github-remote-url\", \n        type=str, \n        help=\"GitHub remote repository URL\"\n    )\n    parser.add_argument(\n        \"--github-token\", \n        type=str, \n        help=\"GitHub authentication token\"\n    )\n    \n    return parser.parse_args()\n\n\ndef get_requirement_text(args: argparse.Namespace) -> Optional[str]:\n    \"\"\"Get requirement text from arguments or file.\"\"\"\n    if args.requirement:\n        return args.requirement\n    elif args.requirement_file:\n        try:\n            with open(args.requirement_file, 'r', encoding='utf-8') as file:\n                return file.read()\n        except IOError as e:\n            print(f\"Error reading requirement file: {e}\", file=sys.stderr)\n            return None\n    else:\n        print(\"No requirement specified. Use --requirement or --requirement-file\", file=sys.stderr)\n        return None\n\n\ndef build_config_from_args(args: argparse.Namespace) -> Dict[str, Any]:\n    \"\"\"Build WorkflowEngineConfig parameters from command line arguments.\"\"\"\n    config_params = {\n        \"project_dir\": args.project_dir,\n        \"issue_id\": args.issue_id,\n        \"core_model\": args.core_model,\n        \"data_model\": args.data_model,\n        \"core_template\": args.core_temperature,  # Note: using template to match original param name\n        \"data_template\": args.data_temperature,  # Note: using template to match original param name\n        \"max_retry\": args.max_retry,\n        \"default_branch\": args.default_branch,\n        \"mode\": args.mode,\n    }\n    \n    # Add optional parameters if they're specified\n    if args.base_url:\n        config_params[\"base_url\"] = args.base_url\n    if args.api_key:\n        config_params[\"api_key\"] = args.api_key\n    if args.github_remote_url:\n        config_params[\"github_remote_url\"] = args.github_remote_url\n    if args.github_token:\n        config_params[\"github_token\"] = args.github_token\n        \n    return config_params\n",
    "is_create": false,
    "is_modify": true,
    "is_delete": false
  },
  {
    "file_name": "scripts/run_bot.sh",
    "content": "diff\n--- scripts/run_bot.sh\n+++ scripts/run_bot.sh\n@@ -2,15 +2,50 @@\n \n # 启动bella-issues-bot的帮助脚本\n # 此脚本简化了命令行参数的输入，便于快速使用\n+# 支持简化的参数选项，调用Python客户端模块\n+\n+show_help() {\n+    echo \"使用方法: $0 <issue-id> [选项] [需求文件路径]\"\n+    echo \"\"\n+    echo \"必需参数:\"\n+    echo \"  <issue-id>               问题ID（必填）\"\n+    echo \"\"\n+    echo \"选项:\"\n+    echo \"  -m, --model MODEL        同时设置core和data模型名称\"\n+    echo \"  -t, --temp TEMP          同时设置core和data模型温度\"\n+    echo \"  --cm, --core-model MODEL 单独设置core模型名称\"\n+    echo \"  --dm, --data-model MODEL 单独设置data模型名称\"\n+    echo \"  --ct, --core-temp TEMP   单独设置core模型温度\"\n+    echo \"  --dt, --data-temp TEMP   单独设置data模型温度\"\n+    echo \"  -k, --key KEY            设置API密钥\"\n+    echo \"  -h, --help               显示此帮助信息\"\n+    echo \"\"\n+    echo \"示例:\"\n+    echo \"  $0 42 ./requirements.txt             # 使用文件中的需求\"\n+    echo \"  $0 42 -m gpt-4-turbo                # 设置所有模型为gpt-4-turbo\"\n+    echo \"  $0 42 -m gpt-4-turbo -t 0.9         # 设置所有模型为gpt-4-turbo，温度为0.9\"\n+    echo \"  $0 42 --cm gpt-4-turbo --dm gpt-3.5-turbo  # 分别设置不同模型\"\n+    echo \"\"\n+}\n+\n+# 检查是否请求帮助\n+if [ \"$1\" == \"-h\" ] || [ \"$1\" == \"--help\" ]; then\n+    show_help\n+    exit 0\n+fi\n \n # 检查是否提供了issue-id参数\n-if [ -z \"$1\" ]; then\n-    echo \"使用方法: $0 <issue-id> [需求文件路径]\"\n-    echo \"\"\n-    echo \"示例:\"\n-    echo \"  $0 42 ./requirements.txt  # 使用文件中的需求\"\n-    echo \"  $0 42                    # 将会要求您输入需求\"\n+if [ -z \"$1\" ] || [[ \"$1\" == -* ]]; then\n+    echo \"错误: 必须提供issue-id作为第一个参数\"\n+    show_help\n     exit 1\n fi\n \n-python -m client.terminal --issue-id \"$1\" ${2:+--requirement-file \"$2\"}\n+ISSUE_ID=$1\n+shift  # 移除第一个参数，使其他参数可以按顺序处理\n+\n+# 检查最后一个参数是否是一个文件（不以连字符开头）\n+ARGS=(\"$@\")\n+if [ ${#ARGS[@]} -gt 0 ] && [[ ! \"${ARGS[-1]}\" == -* ]] && [ -f \"${ARGS[-1]}\" ]; then\n+    python -m client.terminal -i $ISSUE_ID --requirement-file \"${ARGS[-1]}\" \"${ARGS[@]:0:${#ARGS[@]}-1}\"\n+else\n+    python -m client.terminal -i $ISSUE_ID \"$@\"\n+fi\n\n",
    "file_content": "#!/bin/bash\n\n# 启动bella-issues-bot的帮助脚本\n# 此脚本简化了命令行参数的输入，便于快速使用\n\n# 检查是否提供了issue-id参数\nif [ -z \"$1\" ]; then\n    echo \"使用方法: $0 <issue-id> [需求文件路径]\"\n    echo \"\"\n    echo \"示例:\"\n    echo \"  $0 42 ./requirements.txt  # 使用文件中的需求\"\n    echo \"  $0 42                    # 将会要求您输入需求\"\n    exit 1\nfi\n\npython -m client.terminal --issue-id \"$1\" ${2:+--requirement-file \"$2\"}\n",
    "is_create": false,
    "is_modify": true,
    "is_delete": false
  },
  {
    "file_name": "client/terminal.py",
    "content": "diff\n--- client/terminal.py\n+++ client/terminal.py\n@@ -4,7 +4,7 @@\n \"\"\"\n import logging\n import os\n-import sys \n+import sys\n from dotenv import load_dotenv\n \n from core.workflow_engine import WorkflowEngine, WorkflowEngineConfig\n@@ -34,7 +34,7 @@\n     # Try to get API key from environment if not provided as argument\n     if \"api_key\" not in config_params and os.environ.get(\"OPENAI_API_KEY\"):\n         config_params[\"api_key\"] = os.environ.get(\"OPENAI_API_KEY\")\n-        \n+    \n     # Create the workflow engine config\n     config = WorkflowEngineConfig(**config_params)\n     \n\n",
    "file_content": "\"\"\"\nTerminal entrypoint for the WorkflowEngine.\nProvides functionality to run the engine from terminal with command-line arguments.\n\"\"\"\nimport logging\nimport os\nimport sys \nfrom dotenv import load_dotenv\n\nfrom core.workflow_engine import WorkflowEngine, WorkflowEngineConfig\nfrom client.cli import parse_args, get_requirement_text, build_config_from_args\nfrom core.log_config import setup_logging\n\n\ndef run_workflow_from_terminal() -> str:\n    \"\"\"\n    Main entry point for running the workflow engine from terminal.\n    Parses command line arguments and runs the workflow engine.\n    \"\"\"\n    # Load environment variables from .env file if present\n    load_dotenv()\n    \n    # Parse command line arguments\n    args = parse_args()\n    \n    # Get requirement text\n    requirement = get_requirement_text(args)\n    if not requirement:\n        sys.exit(1)\n    \n    # Build config from arguments\n    config_params = build_config_from_args(args)\n    \n    # Try to get API key from environment if not provided as argument\n    if \"api_key\" not in config_params and os.environ.get(\"OPENAI_API_KEY\"):\n        config_params[\"api_key\"] = os.environ.get(\"OPENAI_API_KEY\")\n        \n    # Create the workflow engine config\n    config = WorkflowEngineConfig(**config_params)\n    \n    # Initialize and run the workflow engine\n    engine = WorkflowEngine(config)\n    response = engine.process_requirement(requirement)\n    \n    # Print the response to the terminal if available\n    if response:\n        print(f\"\\nResponse:\\n{response}\")\n    \n    return response if response else \"\"\n\n\nif __name__ == \"__main__\":\n    setup_logging(log_level=logging.INFO)\n    response = run_workflow_from_terminal()\n",
    "is_create": false,
    "is_modify": true,
    "is_delete": false
  },
  {
    "file_name": "client/runner.py",
    "content": "diff\n--- client/runner.py\n+++ client/runner.py\n@@ -15,8 +15,10 @@\n     issue_id: int,\n     requirement: str,\n     project_dir: Optional[str] = None,\n-    core_model: str = \"gpt-4o\",\n-    data_model: str = \"gpt-4o\",\n+    model: Optional[str] = None,  # 统一的模型设置\n+    core_model: Optional[str] = \"gpt-4o\",\n+    data_model: Optional[str] = None,  # 默认与core_model相同\n+    temperature: Optional[float] = None,  # 统一的温度设置\n     core_temperature: float = 0.7,\n     data_temperature: float = 0.7,\n     max_retry: int = 3,\n@@ -36,11 +38,24 @@\n     if project_dir is None:\n         project_dir = os.getcwd()\n     \n+    # 处理统一的模型配置\n+    if model is not None:\n+        core_model = model\n+        data_model = model\n+    \n+    # 如果未指定data_model，则默认与core_model相同\n+    if data_model is None:\n+        data_model = core_model\n+    \n+    # 处理统一的温度配置\n+    if temperature is not None:\n+        core_temperature = temperature\n+        data_temperature = temperature\n+    \n     # Create config with provided parameters\n     config = WorkflowEngineConfig(\n-        project_dir=project_dir, issue_id=issue_id, core_model=core_model,\n-        data_model=data_model, core_template=core_temperature, data_template=data_temperature,\n-        max_retry=max_retry, default_branch=default_branch, mode=mode,\n+        project_dir=project_dir, issue_id=issue_id, \n+        core_model=core_model, data_model=data_model,\n+        core_template=core_temperature, data_template=data_temperature,\n+        max_retry=max_retry, default_branch=default_branch, mode=mode, \n         base_url=base_url, api_key=api_key, github_remote_url=github_remote_url,\n         github_token=github_token, **kwargs\n     )\n\n",
    "file_content": "\"\"\"\nProgrammatic API for running the WorkflowEngine.\nProvides a simplified interface for use in Python scripts.\n\"\"\"\n\nimport os\nfrom typing import Optional, Dict, Any, Union\n\nfrom dotenv import load_dotenv\n\nfrom core.workflow_engine import WorkflowEngine, WorkflowEngineConfig\n\n\ndef run_workflow(\n    issue_id: int,\n    requirement: str,\n    project_dir: Optional[str] = None,\n    core_model: str = \"gpt-4o\",\n    data_model: str = \"gpt-4o\",\n    core_temperature: float = 0.7,\n    data_temperature: float = 0.7,\n    max_retry: int = 3,\n    default_branch: str = \"main\",\n    mode: str = \"client\",\n    base_url: Optional[str] = None,\n    api_key: Optional[str] = None,\n    github_remote_url: Optional[str] = None,\n    github_token: Optional[str] = None,\n    **kwargs: Dict[str, Any]\n) -> None:\n    \"\"\"Run the WorkflowEngine with the given configuration.\"\"\"\n    # Load environment variables\n    load_dotenv()\n    \n    # Use current directory if no project_dir specified\n    if project_dir is None:\n        project_dir = os.getcwd()\n    \n    # Create config with provided parameters\n    config = WorkflowEngineConfig(\n        project_dir=project_dir, issue_id=issue_id, core_model=core_model,\n        data_model=data_model, core_template=core_temperature, data_template=data_temperature,\n        max_retry=max_retry, default_branch=default_branch, mode=mode,\n        base_url=base_url, api_key=api_key, github_remote_url=github_remote_url,\n        github_token=github_token, **kwargs\n    )\n    \n    # Run the workflow engine\n    engine = WorkflowEngine(config)\n    response = engine.process_requirement(requirement)\n    \n    return response\n",
    "is_create": false,
    "is_modify": true,
    "is_delete": false
  }
]