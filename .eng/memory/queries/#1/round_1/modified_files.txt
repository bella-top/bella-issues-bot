[
  {
    "file_name": "",
    "content": "Diff #1:\ndiff\n--- core/file_memory.py\n+++ core/file_memory.py\n@@ -10,6 +10,7 @@ from langchain.tools import Tool\n from core.ai import AIAssistant, AIConfig\n from core.file_fetcher import FileFetcher\n from core.git_manager import GitManager, GitConfig\n+from core.log_manager import LogManager\n from core.log_config import get_logger\n \n logger = get_logger(__name__)\n@@ -19,6 +20,7 @@ logger = get_logger(__name__)\n class FileMemoryConfig:\n     \"\"\"配置文件记忆管理\"\"\"\n     project_dir: str\n+    log_manager: Optional[LogManager] = None\n     ai_config: AIConfig\n     git_manager: GitManager\n \n@@ -42,6 +44,9 @@ class FileMemory:\n         self.memory_path = os.path.join(config.project_dir, self.FILE_DETAILS_PATH)\n         self.git_id_path = os.path.join(config.project_dir, self.GIT_ID_FILE)\n \n+        # 保存LogManager引用\n+        self.log_manager = config.log_manager\n+\n         # 初始化 AI 助手\n         self.ai_assistant = AIAssistant(config=self.config.ai_config, tools=[self._create_batch_description_tool()])\n \n@@ -348,6 +353,39 @@ class FileMemory:\n         except Exception as e:\n             logger.error(f\"读取文件描述失败: {str(e)}\")\n             return {}\n+            \n+    def _get_last_round_modified_files(self) -> set:\n+        \"\"\"\n+        从LogManager获取上一轮修改的文件列表\n+        \n+        Returns:\n+            set: 上一轮修改的文件路径集合\n+        \"\"\"\n+        if not self.log_manager:\n+            logger.info(\"未提供LogManager，无法获取上一轮修改的文件\")\n+            return set()\n+        \n+        try:\n+            # 获取当前轮次\n+            current_round = self.log_manager.get_current_round()\n+            \n+            # 获取上一轮的日志条目\n+            if current_round > 1:\n+                prev_round = current_round - 1\n+                log_entry = self.log_manager.get_issue_round_log_entry(prev_round, include_diff=True)\n+                \n+                if log_entry and log_entry.modified_files:\n+                    # 从diff_info中提取文件路径\n+                    modified_files = set()\n+                    for diff_info in log_entry.modified_files:\n+                        if diff_info.file_path:\n+                            modified_files.add(diff_info.file_path)\n+                    \n+                    logger.info(f\"从LogManager获取到上一轮({prev_round})修改的文件: {len(modified_files)}个\")\n+                    return modified_files\n+            return set()\n+        except Exception as e:\n+            logger.error(f\"获取上一轮修改的文件失败: {str(e)}\")\n+            return set()\n \n if __name__ == \"__main__\":\n     load_dotenv()\n@@ -355,6 +393,7 @@ if __name__ == \"__main__\":\n     memory = FileMemory(\n         FileMemoryConfig(\n             ai_config=AIConfig(temperature=1, model_name=\"claude-3.7-sonnet\"),\n+            log_manager=None,\n             git_manager=GitManager(config=GitConfig(project_dir))\n         )\n     )\n\n\n\nDiff #2:\ndiff\n--- core/file_memory.py\n+++ core/file_memory.py\n@@ -3,7 +3,7 @@ import os\n import time\n from dataclasses import dataclass\n from typing import Dict, List\n-\n+from typing import Dict, List, Optional, Set\n from dotenv import load_dotenv\n from langchain.tools import Tool\n \n@@ -357,14 +357,16 @@ class FileMemory:\n     def update_file_details(self) -> None:\n         \"\"\"更新文件描述信息\"\"\"\n         # 获取当前的 Git ID\n-        current_git_id = self.git_manager.get_current_commit_id()\n-        saved_git_id = self._read_git_id()\n+        current_git_id = self.git_manager.get_current_commit_id() \n+        saved_git_id = self._read_git_id() \n \n         # 获取所有文件\n         all_files = FileFetcher.get_all_files_without_ignore(self.config.project_dir)\n+        \n+        # 获取LogManager中上一轮修改的文件\n+        log_modified_files = self._get_last_round_modified_files()\n \n         # 读取现有描述\n         existing_details = self._read_file_details()\n \n         if saved_git_id:\n@@ -372,8 +374,11 @@ class FileMemory:\n             changed_files = set(\n                 self.git_manager.get_changed_files(saved_git_id, current_git_id)\n             ) & all_files\n+            \n+            # 合并Git变更和LogManager中的变更\n+            changed_files = changed_files.union(log_modified_files)\n+            \n             new_files = all_files - set(existing_details.keys())\n             files_to_process = list(changed_files | new_files)\n \n \n@@ -382,7 +387,8 @@ class FileMemory:\n                 k: v for k, v in existing_details.items() if k in all_files\n             }\n         else:\n-            # 首次运行，处理所有文件\n+            # 首次运行，处理所有文件 \n+            # 如果有LogManager变更，优先处理它们\n             files_to_process = list(all_files)\n \n         # 处理需要更新的文件\n@@ -390,6 +396,10 @@ class FileMemory:\n             new_descriptions = self._process_files_chunk(files_to_process)\n             existing_details.update(new_descriptions)\n \n+            # 记录处理的文件数量\n+            logger.info(f\"共处理了{len(files_to_process)}个文件，其中上一轮修改的文件有{len(log_modified_files)}个，\"\n+                       f\"Git变更文件有{len(changed_files) - len(log_modified_files) if 'changed_files' in locals() else 0}个\")\n+\n         # 保存结果\n         self._write_file_details(existing_details)\n         self._write_git_id(current_git_id)\n\n\n\nDiff #3:\ndiff\n--- core/file_memory.py\n+++ core/file_memory.py\n@@ -361,7 +361,7 @@ class FileMemory:\n         saved_git_id = self._read_git_id() \n \n         # 获取所有文件\n-        all_files = FileFetcher.get_all_files_without_ignore(self.config.project_dir)\n+        all_files = set(FileFetcher.get_all_files_without_ignore(self.config.project_dir))\n         \n         # 获取LogManager中上一轮修改的文件\n         log_modified_files = self._get_last_round_modified_files()\n@@ -374,6 +374,9 @@ class FileMemory:\n             changed_files = set(\n                 self.git_manager.get_changed_files(saved_git_id, current_git_id)\n             ) & all_files\n+\n+            # 记录Git变更信息\n+            logger.info(f\"从Git获取到变更文件: {len(changed_files)}个\")\n             \n             # 合并Git变更和LogManager中的变更\n             changed_files = changed_files.union(log_modified_files)\n@@ -381,6 +384,8 @@ class FileMemory:\n             new_files = all_files - set(existing_details.keys())\n             files_to_process = list(changed_files | new_files)\n \n+            # 记录新文件信息\n+            logger.info(f\"检测到新文件: {len(new_files)}个\")\n \n             # 删除不存在的文件的描述\n             existing_details = {\n@@ -396,9 +401,11 @@ class FileMemory:\n             new_descriptions = self._process_files_chunk(files_to_process)\n             existing_details.update(new_descriptions)\n \n-            # 记录处理的文件数量\n-            logger.info(f\"共处理了{len(files_to_process)}个文件，其中上一轮修改的文件有{len(log_modified_files)}个，\"\n-                       f\"Git变更文件有{len(changed_files) - len(log_modified_files) if 'changed_files' in locals() else 0}个\")\n+            # 记录处理结果\n+            log_files_count = len(log_modified_files)\n+            git_files_count = len(changed_files - log_modified_files) if 'changed_files' in locals() else 0\n+            logger.info(f\"共处理了{len(files_to_process)}个文件，其中上一轮修改的文件有{log_files_count}个，\"\n+                       f\"Git变更文件有{git_files_count}个\")\n \n         # 保存结果\n         self._write_file_details(existing_details)\n\n\n\nDiff #4:\ndiff\n--- core/file_memory.py\n+++ core/file_memory.py\n@@ -2,7 +2,7 @@ import json\n import os\n import time\n from dataclasses import dataclass\n-from typing import Dict, List\n+from typing import Dict, List, Optional, Set\n from typing import Dict, List, Optional, Set\n from dotenv import load_dotenv\n from langchain.tools import Tool\n\n\n\nDiff #5:\ndiff\n--- core/file_memory.py\n+++ core/file_memory.py\n@@ -2,8 +2,7 @@ import json\n import os\n import time\n from dataclasses import dataclass\n-from typing import Dict, List, Optional, Set\n-from typing import Dict, List, Optional, Set\n+from typing import Dict, List, Optional, Set, Union\n from dotenv import load_dotenv\n from langchain.tools import Tool\n\n",
    "file_content": "import json\nimport os\nimport time\nfrom dataclasses import dataclass\nfrom typing import Dict, List\n\nfrom dotenv import load_dotenv\nfrom langchain.tools import Tool\n\nfrom core.ai import AIAssistant, AIConfig\nfrom core.file_fetcher import FileFetcher\nfrom core.git_manager import GitManager, GitConfig\nfrom core.log_config import get_logger\n\nlogger = get_logger(__name__)\n\n\n@dataclass\nclass FileMemoryConfig:\n    \"\"\"配置文件记忆管理\"\"\"\n    project_dir: str\n    ai_config: AIConfig\n    git_manager: GitManager\n\n\nclass FileMemory:\n    \"\"\"管理文件描述的记忆\"\"\"\n\n    MEMORY_DIR = \".eng/memory\"\n    FILE_DETAILS_PATH = f\"{MEMORY_DIR}/file_details.txt\"\n    GIT_ID_FILE = f\"{MEMORY_DIR}/git_id\"\n    MAX_RETRIES = 3    # 最大重试次数\n    RETRY_DELAY = 30    # 重试延迟（秒）\n    # 每批次最大行数和字符数限制\n    MAX_LINES_PER_BATCH = 10000  # 最大行数\n    MAX_CHARS_PER_BATCH = 100000  # 最大字符数，约为 100KB\n    MAX_FILES_PER_BATCH = 100  # 每批次最多处理的文件数\n\n    def __init__(self, config: FileMemoryConfig):\n        self.config = config\n        self.memory_path = os.path.join(config.project_dir, self.FILE_DETAILS_PATH)\n        self.git_id_path = os.path.join(config.project_dir, self.GIT_ID_FILE)\n\n        # 初始化 AI 助手\n        self.ai_assistant = AIAssistant(config=self.config.ai_config, tools=[self._create_batch_description_tool()])\n\n        # 初始化 Git 管理器\n        self.git_manager = self.config.git_manager\n\n        # 确保内存目录存在\n        os.makedirs(os.path.dirname(self.memory_path), exist_ok=True)\n\n    def _ensure_directories(self):\n        \"\"\"确保必要的目录存在\"\"\"\n        memory_dir = os.path.join(self.config.project_dir, self.MEMORY_DIR)\n        os.makedirs(memory_dir, exist_ok=True)\n\n    def _get_failed_files_path(self) -> str:\n        \"\"\"获取失败文件记录的路径\"\"\"\n        return os.path.join(self.config.project_dir, self.MEMORY_DIR, \"failed_files.json\")\n\n    def _read_failed_files(self) -> List[str]:\n        \"\"\"读取处理失败的文件列表\"\"\"\n        failed_files_path = self._get_failed_files_path()\n        if os.path.exists(failed_files_path):\n            try:\n                with open(failed_files_path, 'r', encoding='utf-8') as f:\n                    return json.load(f)\n            except Exception as e:\n                logger.error(f\"读取失败文件列表出错: {str(e)}\")\n        return []\n\n    def _write_failed_files(self, failed_files: List[str]) -> None:\n        \"\"\"写入处理失败的文件列表\"\"\"\n        failed_files_path = self._get_failed_files_path()\n        try:\n            with open(failed_files_path, 'w', encoding='utf-8') as f:\n                json.dump(failed_files, f, ensure_ascii=False, indent=2)\n        except Exception as e:\n            logger.error(f\"写入失败文件列表出错: {str(e)}\")\n\n    def _create_batch_description_tool(self) -> Tool:\n        \"\"\"创建批量生成文件描述的工具\"\"\"\n        from langchain.tools import Tool\n        \n        def process_file_descriptions(file_descriptions: str) -> Dict[str, str]:\n            \"\"\"\n            处理文件描述列表\n            \n            Args:\n                file_descriptions: JSON格式的文件描述列表，格式为 [{\"fileName\": \"path/to/file.py\", \"desc\": \"文件描述\"}]\n                \n            Returns:\n                Dict[str, str]: 文件路径到描述的映射\n            \"\"\"\n            try:\n                descriptions = {}\n                file_list = json.loads(file_descriptions)\n                \n                if not isinstance(file_list, list):\n                    logger.error(\"错误：输入必须是一个列表\")\n                    return descriptions\n                \n                # 处理结果\n                for item in file_list:\n                    if isinstance(item, dict) and \"fileName\" in item and \"desc\" in item:\n                        descriptions[item[\"fileName\"]] = item[\"desc\"]\n                    else:\n                        logger.warning(f\"跳过无效的文件描述项: {item}\")\n                \n                logger.info(f\"成功处理了 {len(descriptions)} 个文件描述\")\n                return descriptions\n            except json.JSONDecodeError:\n                logger.error(\"错误：输入不是有效的 JSON 格式\")\n                return {}\n            except Exception as e:\n                logger.error(f\"处理文件描述时出错: {str(e)}\")\n                return {}\n        \n        return Tool(\n            name=\"process_file_descriptions\",\n            description=\"处理文件描述列表，输入必须是JSON格式的列表，每个元素包含fileName和desc字段\",\n            func=process_file_descriptions,\n            return_direct=True\n        )\n\n    def _generate_batch_file_descriptions(self, files_with_content: List[Dict[str, str]]) -> Dict[str, str]:\n        \"\"\"\n        批量生成文件描述\n        \n        Args:\n            files_with_content: 包含文件路径和内容的列表，格式为 [{\"filepath\": \"path/to/file.py\", \"content\": \"...\"}]\n            \n        Returns:\n            Dict[str, str]: 文件路径到描述的映射\n        \"\"\"\n        # 构建提示词\n        files_text = \"\"\n        for i, file_info in enumerate(files_with_content):\n            files_text += f\"\\n--- 文件 {i+1}: {file_info['filepath']} ---\\n{file_info['content']}\\n\"\n        \n        prompt = f\"\"\"\n请分析以下多个代码文件，并为每个文件生成一个简短的中文描述（每个不超过100字）。\n描述应该包含：\n1. 文件的主要功能\n2. 包含的关键类或函数\n3. 与其他文件的主要交互（如果明显的话）\n\n{files_text}\n\n请使用process_file_descriptions工具返回结果，输入必须是一个JSON格式的列表，每个元素包含fileName和desc字段。\n例如：\n[\n  {{\"fileName\": \"path/to/file1.py\", \"desc\": \"这个文件实现了...\"}},\n  {{\"fileName\": \"path/to/file2.py\", \"desc\": \"这个文件定义了...\"}}\n]\n\n请确保每个文件都有对应的描述，并且描述准确反映文件的功能和内容。\n\"\"\"\n        \n        # 尝试生成描述，最多重试MAX_RETRIES次\n        descriptions = {}\n        failed_files = []\n        file_paths = [file_info[\"filepath\"] for file_info in files_with_content]\n        \n        for attempt in range(self.MAX_RETRIES):\n            try:\n                logger.info(f\"尝试批量生成文件描述（第{attempt+1}次尝试）\")\n                \n                # 使用工具生成描述\n                descriptions = self.ai_assistant.generate_response(prompt, use_tools=True)\n                \n                # 如果返回的不是字典，可能是字符串响应\n                if not isinstance(descriptions, dict):\n                    logger.error(f\"工具返回了非预期的结果类型: {type(descriptions)}\")\n                    descriptions = {}\n                \n                # 检查是否所有文件都有描述\n                missing_files = [\n                    file_path for file_path in file_paths\n                    if file_path not in descriptions\n                ]\n                \n                if missing_files:\n                    failed_files.extend(missing_files)\n                    logger.warning(f\"以下文件未能生成描述: {missing_files}\")\n                \n                # 如果有成功处理的文件，则返回结果\n                if descriptions:\n                    return descriptions\n            \n            except Exception as e:\n                logger.error(f\"批量生成文件描述失败（第{attempt+1}次尝试）: {str(e)}\")\n            \n            # 如果不是最后一次尝试，则等待后重试\n            if attempt < self.MAX_RETRIES - 1:\n                logger.info(f\"等待 {self.RETRY_DELAY} 秒后重试...\")\n                time.sleep(self.RETRY_DELAY)\n        \n        # 所有尝试都失败，记录失败的文件\n        self._update_failed_files(file_paths)\n        \n        # 返回空结果\n        return descriptions\n\n    def _update_failed_files(self, new_failed_files: List[str]) -> None:\n        \"\"\"更新失败文件列表\"\"\"\n        if not new_failed_files:\n            return\n            \n        # 读取现有失败文件列表\n        existing_failed_files = self._read_failed_files()\n        \n        # 合并并去重\n        all_failed_files = list(set(existing_failed_files + new_failed_files))\n        \n        # 写入更新后的列表\n        self._write_failed_files(all_failed_files)\n        logger.info(f\"更新了失败文件列表，共 {len(all_failed_files)} 个文件\")\n\n    def process_failed_files(self) -> Dict[str, str]:\n        \"\"\"处理之前失败的文件\"\"\"\n        failed_files = self._read_failed_files()\n        if not failed_files:\n            logger.info(\"没有需要处理的失败文件\")\n            return {}\n            \n        logger.info(f\"开始处理 {len(failed_files)} 个失败文件\")\n        \n        # 准备文件内容\n        files_with_content = []\n        for filepath in failed_files:\n            content = self._get_file_content(filepath)\n            if content.strip():  # 跳过空文件\n                files_with_content.append({\"filepath\": filepath, \"content\": content})\n        \n        # 按批次处理文件\n        descriptions = self._process_files_in_batches(files_with_content)\n        \n        # 更新失败文件列表\n        if descriptions:\n            # 找出成功处理的文件\n            processed_files = list(descriptions.keys())\n            # 更新失败文件列表\n            new_failed_files = [f for f in failed_files if f not in processed_files]\n            self._write_failed_files(new_failed_files)\n            \n            logger.info(f\"成功处理了 {len(processed_files)} 个之前失败的文件，还有 {len(new_failed_files)} 个文件失败\")\n        \n        return descriptions\n\n\n    def _get_file_content(self, filepath: str) -> str:\n        \"\"\"获取文件内容\"\"\"\n        try:\n            full_path = os.path.join(self.config.project_dir, filepath)\n            with open(full_path, \"r\", encoding=\"utf-8\") as f:\n                return f.read()\n        except Exception as e:\n            logger.error(f\"读取文件 {filepath} 失败: {str(e)}\")\n            return \"\"\n\n    def _process_files_in_batches(self, files_with_content: List[Dict[str, str]]) -> Dict[str, str]:\n        \"\"\"将文件分批处理\"\"\"\n        all_descriptions = {}\n        current_batch = []\n        current_lines = 0\n        current_size = 0\n\n        \n        for file_info in files_with_content:\n            content = file_info[\"content\"]\n            lines = len(content.splitlines())\n            chars = len(content)\n            \n            if lines == 0:\n                continue\n                \n            # 检查是否需要开始新批次\n            # 如果当前批次已满或添加此文件会超出限制，则处理当前批次并开始新批次\n            if (current_batch and (\n                len(current_batch) >= self.MAX_FILES_PER_BATCH or\n                current_lines + lines > self.MAX_LINES_PER_BATCH or\n                current_size + chars > self.MAX_CHARS_PER_BATCH\n            )):\n                # 处理当前批次\n                logger.info(f\"处理批次: {len(current_batch)} 个文件，共 {current_lines} 行，{current_size} 字符\")\n                batch_descriptions = self._generate_batch_file_descriptions(current_batch)\n                all_descriptions.update(batch_descriptions)\n                \n                # 重置批次\n                current_batch = [file_info]\n                current_lines = lines\n                current_size = chars\n            else:\n                current_batch.append(file_info)\n                current_lines += lines\n                current_size += chars\n        \n        # 处理最后一个批次\n        if current_batch:\n            logger.info(f\"处理最后一个批次: {len(current_batch)} 个文件，共 {current_lines} 行，{current_size} 字符\")\n            batch_descriptions = self._generate_batch_file_descriptions(current_batch)\n            all_descriptions.update(batch_descriptions)\n        \n        return all_descriptions\n\n    def _process_files_chunk(self, files: List[str]) -> Dict[str, str]:\n        \"\"\"处理一组文件，生成描述\"\"\"\n        # 准备文件内容\n        files_with_content = []\n        for filepath in files:\n            content = self._get_file_content(filepath)\n            if content.strip():  # 跳过空文件\n                files_with_content.append({\"filepath\": filepath, \"content\": content})\n        \n        # 按批次处理文件\n        return self._process_files_in_batches(files_with_content)\n\n    def _read_git_id(self) -> str:\n        \"\"\"读取保存的 Git ID\"\"\"\n        if not os.path.exists(self.git_id_path):\n            return \"\"\n        with open(self.git_id_path, \"r\") as f:\n            return f.read().strip()\n\n    def _write_git_id(self, git_id: str) -> None:\n        \"\"\"写入当前 Git ID\"\"\"\n        with open(self.git_id_path, \"w\") as f:\n            f.write(git_id)\n\n    def _read_file_details(self) -> Dict[str, str]:\n        \"\"\"读取文件描述信息\"\"\"\n        if not os.path.exists(self.memory_path):\n            return {}\n\n        details = {}\n        with open(self.memory_path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                if \":\" in line:\n                    filename, description = line.strip().split(\":\", 1)\n                    details[filename] = description\n        return details\n\n    def _write_file_details(self, details: Dict[str, str]) -> None:\n        \"\"\"写入文件描述信息\"\"\"\n        with open(self.memory_path, \"w\", encoding=\"utf-8\") as f:\n            for filename, description in sorted(details.items()):\n                f.write(f\"{filename}:{description}\\n\")\n\n    def update_file_details(self) -> None:\n        \"\"\"更新文件描述信息\"\"\"\n        # 获取当前的 Git ID\n        current_git_id = self.git_manager.get_current_commit_id()\n        saved_git_id = self._read_git_id()\n\n        # 获取所有文件\n        all_files = FileFetcher.get_all_files_without_ignore(self.config.project_dir)\n\n        # 读取现有描述\n        existing_details = self._read_file_details()\n\n        if saved_git_id:\n            # 获取变更的文件\n            changed_files = set(\n                self.git_manager.get_changed_files(saved_git_id, current_git_id)\n            ) & all_files\n            new_files = all_files - set(existing_details.keys())\n            files_to_process = list(changed_files | new_files)\n\n\n            # 删除不存在的文件的描述\n            existing_details = {\n                k: v for k, v in existing_details.items() if k in all_files\n            }\n        else:\n            # 首次运行，处理所有文件\n            files_to_process = list(all_files)\n\n        # 处理需要更新的文件\n        if files_to_process:\n            new_descriptions = self._process_files_chunk(files_to_process)\n            existing_details.update(new_descriptions)\n\n        # 保存结果\n        self._write_file_details(existing_details)\n        self._write_git_id(current_git_id)\n\n    @classmethod\n    def get_file_descriptions(cls, project_dir: str) -> Dict[str, str]:\n        \"\"\"获取文件描述的静态方法\"\"\"\n        memory_path = os.path.join(project_dir, cls.FILE_DETAILS_PATH)\n\n        if not os.path.exists(memory_path):\n            return {}\n\n        try:\n            descriptions = {}\n            with open(memory_path, \"r\", encoding=\"utf-8\") as f:\n                for line in f:\n                    if \":\" in line:\n                        filename, description = line.strip().split(\":\", 1)\n                        descriptions[filename] = description\n            return descriptions\n        except Exception as e:\n            logger.error(f\"读取文件描述失败: {str(e)}\")\n            return {}\n\n    @classmethod\n    def get_selected_file_descriptions(cls, project_dir: str, files: List[str]) -> Dict[str, str]:\n        \"\"\"获取文件描述的静态方法\"\"\"\n        memory_path = os.path.join(project_dir, cls.FILE_DETAILS_PATH)\n\n        if not os.path.exists(memory_path):\n            return {}\n        try:\n            descriptions = {}\n            with open(memory_path, \"r\", encoding=\"utf-8\") as f:\n                for line in f:\n                    if \":\" in line:\n                        filename, description = line.strip().split(\":\", 1)\n                        if filename in files:\n                            descriptions[filename] = description\n            return descriptions\n        except Exception as e:\n            logger.error(f\"读取文件描述失败: {str(e)}\")\n            return {}\n\nif __name__ == \"__main__\":\n    load_dotenv()\n    project_dir = \"../.\"\n    memory = FileMemory(\n        FileMemoryConfig(\n            ai_config=AIConfig(temperature=1, model_name=\"claude-3.7-sonnet\"),\n            git_manager=GitManager(config=GitConfig(project_dir))\n        )\n    )\n\n    memory.update_file_details()\n",
    "is_create": false,
    "is_modify": true,
    "is_delete": false
  },
  {
    "file_name": "",
    "content": "diff\n--- core/workflow_engine.py\n+++ core/workflow_engine.py\n@@ -108,11 +108,13 @@ class WorkflowEngine:\n         # 初始化管理器\n         self.git_manager = GitManager(config=self.git_config)\n         self.log_manager = LogManager(config=self.log_config)\n+        \n+        # 初始化文件记忆管理，传入log_manager\n         self.file_memory = FileMemory(\n             config=FileMemoryConfig(\n                 git_manager=self.git_manager,\n                 ai_config=self.core_ai_config,\n-                project_dir=self.project_dir\n+                project_dir=self.project_dir,\n+                log_manager=self.log_manager\n             )\n         )\n         self.version_manager = VersionManager(\n\n",
    "file_content": "import os\nimport shutil\nimport tempfile\nimport uuid\nfrom dataclasses import dataclass\nfrom typing import Optional\n\nfrom core.ai import AIConfig\nfrom core.chat_processor import ChatProcessor, ChatProcessorConfig\nfrom core.code_engineer import CodeEngineer, CodeEngineerConfig\nfrom core.decision import DecisionProcess\nfrom core.diff import Diff\nfrom core.file_memory import FileMemory, FileMemoryConfig\nfrom core.file_selector import FileSelector\nfrom core.git_manager import GitManager, GitConfig\nfrom core.log_config import get_logger\nfrom core.log_manager import LogManager, LogConfig\nfrom core.prompt_generator import PromptGenerator, PromptData\nfrom core.version_manager import VersionManager\n\nlogger = get_logger(__name__)\n\n@dataclass\nclass WorkflowEngineConfig:\n    project_dir: str\n    issue_id:int\n    core_model:str = \"gpt-4o\"\n    data_model:str = \"gpt-4o\"\n    core_template: float = 0.7\n    data_template: float = 0.7\n    max_retry: int = 3,\n    default_branch: str = \"main\"\n    mode: str = \"client\" # [\"client\", \"bot\"] bot模式下，每次进行工作时，会hard reset到issues的最新分支上\n    base_url: Optional[str] = None\n    api_key: Optional[str] = None\n    github_remote_url: Optional[str] =None\n    github_token: Optional[str] = None\n\n\nclass WorkflowEngine:\n    CODE_TIMES = 0\n    CHAT_TIMES = 0\n    \"\"\"\n    工作流引擎，协调版本管理、日志管理和AI交互\n    \"\"\"\n    def __init__(self, config: WorkflowEngineConfig):\n        \"\"\"\n        初始化工作流引擎\n        \n        Args:\n            config: 工作流配置\n        \"\"\"\n        self.CODE_TIMES = 0\n        self.CHAT_TIMES = 0\n        # 存储原始配置\n        self.original_config = config\n        \n        # 根据模式设置工作目录\n        if config.mode == \"bot\":\n            # 创建临时目录作为工作区\n            self.temp_dir = os.path.join(\n                tempfile.gettempdir(), \n                f\"bella-bot-{config.issue_id}-{str(uuid.uuid4())[:8]}\"\n            )\n            os.makedirs(self.temp_dir, exist_ok=True)\n            # 更新配置以使用临时目录\n            self.config = WorkflowEngineConfig(\n                project_dir=self.temp_dir,\n                **{k: v for k, v in vars(config).items() if k != 'project_dir'}\n            )\n            logger.info(f\"Bot模式：创建临时工作目录 {self.temp_dir}\")\n        else:\n            # 客户端模式直接使用指定的目录\n            self.config = config\n            self.temp_dir = None\n\n        self.project_dir = os.path.abspath(self.config.project_dir)\n        # 创建AI配置\n        self.core_ai_config = AIConfig(\n            model_name=config.core_model,\n            temperature=config.core_template,\n            base_url=config.base_url,\n            api_key=config.api_key\n        )\n        \n        self.data_ai_config = AIConfig(\n            model_name=config.data_model,\n            temperature=config.data_template,\n            base_url=config.base_url,\n            api_key=config.api_key\n        )\n        \n        # 创建Git配置\n        self.git_config = GitConfig(\n            repo_path=self.project_dir,\n            remote_url=config.github_remote_url or os.getenv(\"GIT_REMOTE\"),\n            auth_token=config.github_token or os.getenv(\"GITHUB_TOKEN\"),\n            default_branch=config.default_branch\n        )\n        \n        # 创建日志配置\n        self.log_config = LogConfig(\n            project_dir=self.project_dir,\n            issue_id=config.issue_id,\n            mode=config.mode\n        )\n        \n        # 初始化管理器\n        self.git_manager = GitManager(config=self.git_config)\n        self.log_manager = LogManager(config=self.log_config)\n        self.file_memory = FileMemory(\n            config=FileMemoryConfig(\n                git_manager=self.git_manager,\n                ai_config=self.core_ai_config,\n                project_dir=self.project_dir\n            )\n        )\n        self.version_manager = VersionManager(\n            issue_id=config.issue_id,\n            ai_config=self.core_ai_config,\n            log_manager=self.log_manager,\n            git_manager=self.git_manager,\n            file_memory=self.file_memory\n        )\n        self.file_selector = FileSelector(\n            self.project_dir,\n            self.config.issue_id,\n            ai_config=self.core_ai_config\n        )\n\n        # 初始化代码工程师\n        self.code_engineer_config = CodeEngineerConfig(\n            project_dir=self.project_dir,\n            ai_config=self.core_ai_config\n        )\n        self.engineer = CodeEngineer(\n            self.code_engineer_config,\n            self.log_manager,\n            Diff(self.data_ai_config)\n        )\n        \n        # 初始化聊天处理器\n        self.chat_processor = ChatProcessor(\n            ai_config=self.core_ai_config,\n            log_manager=self.log_manager,\n            config=ChatProcessorConfig(system_prompt=\"你是一个项目助手，负责回答关于代码库的问题。下面会给出用户的问题以及相关的项目文件信息。\")\n        )\n        \n        # 初始化决策环境\n        self.decision_env = DecisionProcess(\n            ai_config=self.core_ai_config,\n            version_manager=self.version_manager\n        )\n    \n    def process_requirement(self, user_requirement: str) -> Optional[str]:\n        \"\"\"\n        处理用户需求\n        \n        Args:\n            user_requirement: 用户需求\n\n        Returns:\n            str: 处理结果的响应文本\n        \"\"\"\n        try:\n            # 初始化环境\n            self._setup_environment()\n            \n            response = self._process_requirement_internal(user_requirement)\n            \n            # 如果是bot模式，在结束时清理临时目录\n            if self.config.mode == \"bot\":\n                self._cleanup_environment()\n            \n            return response\n        except Exception as e:\n            logger.error(f\"处理需求时发生错误: {str(e)}\")\n            raise\n\n    def _setup_environment(self) -> None:\n        \"\"\"\n        根据模式设置工作环境\n        \"\"\"\n        if self.config.mode == \"bot\":\n            try:\n                # 重置到issue对应的分支\n                self.git_manager.reset_to_issue_branch(self.config.issue_id)\n                logger.info(f\"成功初始化Bot模式环境，工作目录: {self.temp_dir}\")\n            except Exception as e:\n                logger.error(f\"初始化Bot模式环境失败: {str(e)}\")\n                self._cleanup_environment()\n                raise\n        current_round = self.log_manager.get_current_round()\n\n        # 如果轮次大于1，增量更新上一轮修改的文件详细信息\n        if self.file_memory and current_round > 1:\n            self.file_memory.update_file_details()\n            logger.info(\"已更新文件详细信息\")\n        \n    def _cleanup_environment(self) -> None:\n        \"\"\"\n        清理工作环境，删除临时目录\n        \"\"\"\n        if self.config.mode == \"bot\" and self.temp_dir and os.path.exists(self.temp_dir):\n            try:\n                # 关闭git仓库连接\n                if hasattr(self, 'git_manager') and self.git_manager:\n                    self.git_manager.delete_local_repository()\n                \n                # 删除临时目录\n                shutil.rmtree(self.temp_dir, ignore_errors=True)\n                logger.info(f\"已清理临时工作目录: {self.temp_dir}\")\n            except Exception as e:\n                logger.warning(f\"清理临时目录时出错: {str(e)}\")\n                # 即使清理失败也不抛出异常，让主流程继续\n\n    def _process_requirement_internal(self, user_requirement: str) -> Optional[str]:\n        \"\"\"\n        内部处理需求的方法\n        \n        Args:\n            user_requirement: 用户需求\n            \n        Returns:\n            str: 处理结果\n        \"\"\"\n        # 先通过决策环境分析需求类型\n        decision_result = self.decision_env.analyze_requirement(user_requirement)\n        \n        logger.info(f\"决策结果: 是否需要修改代码={decision_result.needs_code_modification}, \"\n                    f\"理由={decision_result.reasoning}\")\n        \n        if decision_result.needs_code_modification:\n            # 执行代码修改流程\n            # 创建或获取分支名，用于提交\n            branch_name = f\"bella-bot-issues-{self.config.issue_id}\"\n            response = self._run_code_generation_workflow(user_requirement)\n        else: \n            # 执行对话流程\n            response = self._run_chat_workflow(user_requirement)\n        \n        # 如果是Bot模式且有GitHub配置，自动回复到issue\n        if self.config.mode == \"bot\":\n            try:\n                self.version_manager.finalize_changes(mode=self.config.mode, branch_name=branch_name, issue_id=self.config.issue_id, comment_text=response)\n                logger.info(f\"更改已经推送到远端，并添加了Issue评论\")\n            except Exception as e:\n                logger.error(f\"添加Issue评论时出错: {str(e)}\")\n                \n        return response\n    \n    def _run_code_generation_workflow(self, user_requirement: str) -> Optional[str]:\n        \"\"\"\n        执行代码生成流程，基于example_code_generate.py的逻辑\n        \n        Args:\n            user_requirement: 用户需求\n            \n        Returns:\n            str: 处理结果\n        \"\"\"\n        logger.info(\"开始执行代码生成流程\")\n\n        # 确定当前版本\n        requirement, history = self.version_manager.ensure_version_and_generate_context(user_requirement)\n\n        # 生成提示词\n        user_prompt = self._get_user_prompt(requirement, history)\n\n        # 根据提示词修改代码\n        success, response = self.engineer.process_prompt(prompt=user_prompt)\n\n        # 提交更改\n        if success:\n            return response\n        else:\n            self.CODE_TIMES += 1\n            if self.CODE_TIMES >= self.config.max_retry:\n                logger.error(\"code workflow超过最大重试次数\")\n                return self._run_chat_workflow(user_requirement)\n            else:\n                return self._run_code_generation_workflow(user_requirement)\n    \n    def _run_chat_workflow(self, user_requirement: str) -> Optional[str]:\n        \"\"\"\n        执行聊天流程，基于example_chat_process.py的逻辑\n        \n        Args:\n            user_requirement: 用户需求\n            \n        Returns:\n            str: 处理结果\n        \"\"\"\n        logger.info(\"开始执行聊天回复流程\")\n\n        history = self.version_manager.get_formatted_history()\n\n        # 生成提示词\n        user_prompt = self._get_user_prompt(user_requirement, history)\n        \n        # 处理聊天请求\n        response = self.chat_processor.process_chat(user_prompt)\n\n        if(response):\n            return response\n        else:\n            self.CHAT_TIMES += 1\n            if self.CHAT_TIMES >= self.config.max_retry:\n                logger.error(\"chat workflow超过最大重试次数\")\n                return None\n            else:\n                return self._run_chat_workflow(user_requirement)\n\n    def _get_user_prompt(self, requirement: str, history: str) -> str:\n        # 选择文件\n        files = self.file_selector.select_files_for_requirement(requirement)\n        descriptions = FileMemory.get_selected_file_descriptions(self.project_dir, files)\n\n        # 准备提示词数据\n        data = PromptData(\n            requirement=requirement,\n            project_dir=self.project_dir,\n            steps=history,\n            files=files,\n            file_desc=descriptions\n        )\n\n        # 生成提示词\n        return PromptGenerator.generatePrompt(data)\n",
    "is_create": false,
    "is_modify": true,
    "is_delete": false
  }
]